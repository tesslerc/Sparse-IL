{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.distributions import MultivariateNormal\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import gensim\n",
    "import gensim.downloader as glove_api\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as pl\n",
    "import pickle\n",
    "\n",
    "from ZorkGym.text_utils.text_parser import BagOfWords, Word2Vec, TextParser, tokenizer, BasicParser\n",
    "from agents.OMP_DDPG import OMPDDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import sys\n",
    "from scipy.linalg import norm\n",
    "from math import sqrt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hashlib import sha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module implementing the FISTA algorithm\n",
    "\"\"\"\n",
    "__author__ = 'Jean KOSSAIFI'\n",
    "\n",
    "\n",
    "def mixed_norm(coefs, p, q=None, n_samples=None, n_kernels=None):\n",
    "    \"\"\" Computes the (p, q) mixed norm of the vector coefs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs : ndarray\n",
    "        a vector indexed by (l, m)\n",
    "        with l in range(0, n_kernels)\n",
    "            and m in range(0, n_samples)\n",
    "\n",
    "    p : int or np.inf\n",
    "\n",
    "    q : int or np.int\n",
    "\n",
    "    n_samples : int, optional\n",
    "        number of elements in each kernel\n",
    "        default is None\n",
    "\n",
    "    n_kernels : int, optional\n",
    "        number of kernels\n",
    "        default is None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    if q is None or p == q:\n",
    "        return norm(coefs, p)\n",
    "    else:\n",
    "        return norm([norm(i, p) for i in coefs.reshape(\n",
    "            n_kernels, n_samples)], q)\n",
    "\n",
    "\n",
    "def dual_mixed_norm(coefs, n_samples, n_kernels, norm_):\n",
    "    \"\"\" Returns a function corresponding to the dual mixt norm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs : ndarray\n",
    "        a vector indexed by (l, m)\n",
    "        with l in range(0, n_kernels)\n",
    "            and m in range(0, n_samples)\n",
    "\n",
    "    n_samples : int, optional\n",
    "        number of elements in each kernel\n",
    "        default is None\n",
    "\n",
    "    n_kernels : int, optional\n",
    "        number of kernels\n",
    "        default is None\n",
    "\n",
    "    norm_ : {'l11', 'l12', 'l21', 'l22'}\n",
    "        the dual mixed norm we want to compute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    if norm_ == 'l11':\n",
    "        res = norm(coefs, np.inf)\n",
    "    elif norm_ == 'l12':\n",
    "        res = mixed_norm(coefs, np.inf, 2, n_samples, n_kernels)\n",
    "    elif norm_ == 'l21':\n",
    "        res = mixed_norm(coefs, 2, np.inf, n_samples, n_kernels)\n",
    "    else:\n",
    "        res = norm(coefs, 2)\n",
    "    return res\n",
    "\n",
    "\n",
    "def by_kernel_norm(coefs, p, q, n_samples, n_kernels):\n",
    "    \"\"\" Computes the (p, q) norm of coefs for each kernel\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs : ndarray\n",
    "        a vector indexed by (l, m)\n",
    "        with l in range(0, n_kernels)\n",
    "            and m in range(0, n_samples)\n",
    "\n",
    "    p : int or np.inf\n",
    "\n",
    "    q : int or np.inf\n",
    "\n",
    "    n_samples : int, optional\n",
    "        number of elements in each kernel\n",
    "        default is None\n",
    "\n",
    "    n_kernels : int, optional\n",
    "        number of kernels\n",
    "        default is None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of the norms of the sub vectors associated to each kernel\n",
    "    \"\"\"\n",
    "    return [mixed_norm(i, p, q, n_samples, 1)\n",
    "            for i in coefs.reshape(n_kernels, n_samples)]\n",
    "\n",
    "\n",
    "def prox_l11(u, lambda_):\n",
    "    \"\"\" Proximity operator for l(1, 1, 2) norm\n",
    "\n",
    "    \n",
    "\n",
    "    :math:`\\\\hat{\\\\alpha}_{l,m} = sign(u_{l,m})\\\\left||u_{l,m}| - \\\\lambda \\\\right|_+`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray\n",
    "        The vector (of the n-dimensional space) on witch we want\n",
    "        to compute the proximal operator\n",
    "\n",
    "    lambda_ : float\n",
    "        regularisation parameter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray : the vector corresponding to the application of the\n",
    "             proximity operator to u\n",
    "\n",
    "    \"\"\"\n",
    "    return np.sign(u) * np.maximum(np.abs(u) - lambda_, 0.)\n",
    "\n",
    "def prox_l22(u, lambda_):\n",
    "    \"\"\" proximity operator l(2, 2, 2) norm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "     u : ndarray\n",
    "        The vector (of the n-dimensional space) on witch we want to compute the proximal operator\n",
    "\n",
    "    lambda_ : float\n",
    "        regularisation parameter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    ndarray : the vector corresponding to the application of the proximity operator to u\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    :math:`\\\\hat{\\\\alpha}_{l,m} = \\\\frac{1}{1 + \\\\lambda} \\\\, u_{l,m}`\n",
    "\n",
    "    \"\"\"\n",
    "    return 1./(1.+lambda_)*u\n",
    "\n",
    "def prox_l21_1(u, l, n_samples, n_kernels):\n",
    "    \"\"\" Proximity operator l(2, 1, 1) norm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray\n",
    "        The vector (of the n-dimensional space) on witch we want to compute the proximal operator\n",
    "\n",
    "    lambda_ : float\n",
    "        regularisation parameter\n",
    "    \n",
    "    n_samples : int, optional\n",
    "        number of elements in each kernel\n",
    "        default is None\n",
    "\n",
    "    n_kernels : int, optional\n",
    "        number of kernels\n",
    "        default is None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray : the vector corresponding to the application of the proximity operator to u\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    .. math::\n",
    "\n",
    "       \\hat{\\alpha}_{l,m} = u_{l,m} \\left| 1 - \\frac{\\lambda}{\\|u_{l \\bullet}\\|_{2}} \\right|_+\\\n",
    "\n",
    "    where l is in range(0, n_samples) and m is in range(0, n_kernels)\n",
    "    so :math:`u_{l\\\\bullet}` = [u(l, m) for m in n_kernels]\n",
    "\n",
    "    \"\"\"\n",
    "    return (u.reshape(n_kernels, n_samples) *\\\n",
    "        [max(1. - l/norm(u[np.arange(n_kernels)*n_samples+i], 2), 0.)\n",
    "            for i in range(n_samples)]).reshape(-1)\n",
    "\n",
    "\n",
    "def prox_l21(u, l, n_samples, n_kernels):\n",
    "    \"\"\" proximity operator l(2, 1, 2) norm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray\n",
    "        The vector (of the n-dimensional space) on witch we want to compute the proximal operator\n",
    "\n",
    "    lambda_ : float\n",
    "        regularisation parameter\n",
    "\n",
    "    n_samples : int, optional\n",
    "        number of elements in each kernel\n",
    "        default is None\n",
    "\n",
    "    n_kernels : int, optional\n",
    "        number of kernels\n",
    "        default is None\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray : the vector corresponding to the application of the proximity operator to u\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    :math:`\\\\hat{\\\\alpha}_{l,m} = u_{l,m} \\\\left| 1 - \\\\frac{ \\\\lambda}{ \\\\|u_{l \\\\bullet }\\\\|_{2}} \\\\right|_+`\n",
    "\n",
    "    where l is in range(0, n_kernels) and m is in range(0, n_samples)\n",
    "    so :math:`u_{l \\\\bullet }` = [u(l, m) for l in n_samples]\n",
    "\n",
    "    \"\"\"\n",
    "    for i in u.reshape(n_kernels, n_samples):\n",
    "        n = norm(i, 2)\n",
    "        if n==0 or n==np.Inf:\n",
    "            i[:] = 0\n",
    "        else:\n",
    "            i[:] *=  max(1. - l/n, 0.)\n",
    "        # !! If you do just i *= , u isn't modified\n",
    "        # The slice is needed here so that the array can be modified\n",
    "    return u\n",
    "\n",
    "\n",
    "def prox_l12(u, l, n_samples, n_kernels):\n",
    "    \"\"\" proximity operator for l(1, 2, 2) norm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray\n",
    "        The vector (of the n-dimensional space) on witch we want to compute the proximal operator\n",
    "\n",
    "    lambda_ : float\n",
    "        regularisation parameter\n",
    "\n",
    "    n_samples : int, optional\n",
    "        number of elements in each kernel\n",
    "        default is None\n",
    "\n",
    "    n_kernels : int, optional\n",
    "        number of kernels\n",
    "        default is None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray : the vector corresponding to the application of the proximity operator to u\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    :math:`\\\\hat{\\\\alpha}_{l,m} = sign(u_{l,m})\\\\left||u_{l,m}| - \\\\frac{\\\\lambda \\\\sum\\\\limits_{m_l=1}^{M_l} u2_{l,m_l}}{(1+\\\\lambda M_l) \\\\|u_{l \\\\bullet }\\\\|_{2}} \\\\right|_+`\n",
    "\n",
    "    where  :math:`u2_{l,m_l}`  denotes the :math:`|u_{l,m_l}|`\n",
    "        ordered  by descending  order for fixed  :math:`l`,  and the\n",
    "            quantity :math:`M_l` is the number computed in compute_M\n",
    "\n",
    "    \"\"\"\n",
    "    for i in u.reshape(n_kernels, n_samples):\n",
    "        Ml, sum_Ml = compute_M(i, l, n_samples)\n",
    "        # i[:] so that u is really modified\n",
    "        n = norm(i, 2)\n",
    "        if n == 0 or n == np.Inf:\n",
    "            i[:] = 0\n",
    "        else:\n",
    "            i[:] = np.sign(i)*np.maximum(\n",
    "                np.abs(i)-(l*sum_Ml)/((1.+l*Ml)*n), 0.)\n",
    "    return u\n",
    "\n",
    "def compute_M(u, lambda_, n_samples):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray \n",
    "        ndarray of size (n_samples * n_samples) representing a subvector of K,\n",
    "        ie the samples for a single kernel\n",
    "\n",
    "    lambda_ : int\n",
    "\n",
    "    n_samples : int\n",
    "        number of elements in each kernel \n",
    "        ie number of elements of u\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    :math:`M_l` is the number such that\n",
    "\n",
    "    :math:`u2_{l,M_l+1} \\\\leq  \\\\lambda \\\\sum_{m_l=1}^{M_l+1} \\\\left( u2_{l,m_l} - u2_{l,M_l+1}\\\\right)`\n",
    "\n",
    "    and\n",
    "\n",
    "\n",
    "    :math:`u2_{l,M_l} > \\\\lambda\\\\sum_{m_l=1}^{M_l} \\\\left( u2_{l,m_l} - u2_{k,M_l}\\\\right)`\n",
    "\n",
    "    Detailed explication\n",
    "    \n",
    "    let u denotes |u(l)|, the vector associated with the kernel l, ordered by descending order\n",
    "    Ml is the integer such that\n",
    "        u(Ml) <= l * sum(k=1..Ml + 1) (u(k) - u(Ml + 1))    (S1)\n",
    "        and\n",
    "        u(Ml) > l * sum(k=1..Ml) (u(k) - u(Ml)              (S2)\n",
    "    Note that in that definition, Ml is in [1..Ml]\n",
    "    In python, while Ml is in [1..(Ml-1)], indices will be in [0..(Ml-1)], so we must take care of indices.\n",
    "    That's why, we consider Ml is in [0..(Ml-1)] and, at the end, we add 1 to the result\n",
    "\n",
    "    Detailed example\n",
    "\n",
    "    if u(l) = [0 1 2 3] corrsponds to the vector associated with a kernel\n",
    "        then u = |u(l)| ordered by descending order ie u = [3 2 1 0]\n",
    "\n",
    "    Then u = [3 2 1 0]\n",
    "    let l = 1\n",
    "    Ml is in {0, 1, 2} (not 3 because we also consider Ml+1)\n",
    "    # Note : in fact Ml is in {1, 2, 3} but it is more convenient\n",
    "    # to consider it is in {0, 1, 2} as indexing in python starts at 0\n",
    "    # We juste have to add 1 to the final result\n",
    "\n",
    "    if Ml = 0 then S1 = 1 and S2 = 0\n",
    "    if Ml = 1 then S1 = 3 and S2 = 1\n",
    "    if Ml = 2 then S1 = 6 and S2 = 3\n",
    "\n",
    "    if Ml = 0 then u(Ml+1)=u(1)=2  > l*... =1  (S1 is not verified)\n",
    "              and  u(Ml)=u(0)=3    > l*... =0  (S2 is verified)\n",
    "\n",
    "    if Ml = 1 then u(Ml+1)=u(2)=1 <= l*... =3  (S1 is verified)\n",
    "              and  u(Ml)=u(1)=2    > l*... =1  (S2 is verified)\n",
    "\n",
    "    if Ml = 2 then u(Ml+1)=u(3)=0 <= l*... =6  (S1 is verified)\n",
    "              but  u(Ml)=u(2)=1   <= l*... =3  (S1 is not verified)\n",
    "\n",
    "    Conclusion : Ml = 1 + 1 !!\n",
    "    Ml = 2 because in python, indexing starts at 0, so Ml +1\n",
    "\n",
    "    \"\"\"\n",
    "    u = np.sort(np.abs(u))[::-1]\n",
    "    S1 = u[1:] - lambda_*(np.cumsum(u)[:-1] - (np.arange(n_samples-1)+1)*u[1:])\n",
    "    S2 = u[:-1] - lambda_*(np.cumsum(u)[:-1] - (np.arange(n_samples-1)+1)*u[:-1])\n",
    "    Ml = np.argmax((S1<=0.) & (S2>0.)) + 1\n",
    "\n",
    "    return Ml, np.sum(u[:Ml]) # u[:Ml] = u[0, 1, ..., Ml-1] !!\n",
    "\n",
    "\n",
    "def hinge_step(y, K, Z):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    y : np-array\n",
    "        the labels vector\n",
    "\n",
    "    K : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "\n",
    "    Z : a linear combination of the last two coefficient vectors\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples*,_kernels\n",
    "          a point of the space where we will apply gradient descent\n",
    "    \"\"\"\n",
    "    return np.dot(K.transpose(), np.maximum(1 - np.dot(K, Z), 0))\n",
    "\n",
    "def least_square_step(y, K, Z):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    y : np-array\n",
    "        the labels vector\n",
    "\n",
    "    K : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "\n",
    "    Z : a linear combination of the last two coefficient vectors\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples*,_kernels\n",
    "          a point of the space where we will apply gradient descent\n",
    "    \"\"\"\n",
    "    return np.dot(K.transpose(), y - np.dot(K,Z))\n",
    "\n",
    "\n",
    "def _load_Lipschitz_constant(K):\n",
    "    \"\"\" Loads the Lipschitz constant and computes it if not already saved\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    K : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(K).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(K, K.transpose()), 2)\n",
    "        np.save('./.%s.npy' % sha1(K).hexdigest(), mu)\n",
    "    return mu\n",
    "    \n",
    "\n",
    "class Fista(BaseEstimator):\n",
    "    \"\"\"\n",
    "\n",
    "    Fast iterative shrinkage/thresholding Algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    lambda_ : int, optionnal\n",
    "        regularisation parameter\n",
    "        default is 0.5\n",
    "\n",
    "    loss : {'squared-hinge', 'least-square'}, optionnal\n",
    "        the loss function to use\n",
    "        defautl is 'squared-hinge'\n",
    "        \n",
    "    penalty : {'l11', 'l22', 'l12', 'l21'}, optionnal\n",
    "        norm to use as penalty\n",
    "        default is l11\n",
    "\n",
    "    n_iter : int, optionnal\n",
    "        number of iterations\n",
    "        default is 1000\n",
    "\n",
    "    recompute_Lipschitz_constant : bool, optionnal\n",
    "        if True, the Lipschitz constant is recomputed everytime\n",
    "        if False, it is stored based on it's sha1 hash\n",
    "        default is False\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lambda_=0.5, loss='squared-hinge', penalty='l11', n_iter=1000, recompute_Lipschitz_constant=False):\n",
    "        self.n_iter = n_iter\n",
    "        self.lambda_ = lambda_\n",
    "        self.loss = loss\n",
    "        self.penalty = penalty\n",
    "        self.p = int(penalty[1])\n",
    "        self.q = int(penalty[2])\n",
    "        self.recompute_Lipschitz_constant = recompute_Lipschitz_constant\n",
    "\n",
    "    def fit(self, K, y, Lipschitz_constant=None,  verbose=0, **params):\n",
    "        \"\"\" Fits the estimator\n",
    "\n",
    "        We want to solve a problem of the form y = KB + b\n",
    "            where K is a (n_samples, n_kernels*n_samples) matrix.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        K : ndarray\n",
    "            numpy array of shape (n, p)\n",
    "            K is the concatenation of the p/n kernels\n",
    "                where each kernel is of size (n, n)\n",
    "\n",
    "        y : ndarray\n",
    "            an array of the labels to predict for each kernel\n",
    "            y is of size p\n",
    "                where K.shape : (n, p)\n",
    "\n",
    "        Lipschitz_constant : float, optionnal\n",
    "             allow the user to pre-compute the Lipschitz constant\n",
    "             (its computation can be very slow, so that parameter is very\n",
    "             usefull if you were to use several times the algorithm on the same data)\n",
    "\n",
    "        verbose : {0, 1}, optionnal\n",
    "            verbosity of the method : 1 will display informations while 0 will display nothing\n",
    "            default = 0\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        next_step = hinge_step\n",
    "        if self.loss=='squared-hinge':\n",
    "            K = y[:, np.newaxis] * K\n",
    "            # Equivalent to K = np.dot(np.diag(y), X) but faster\n",
    "        elif self.loss=='least-square':\n",
    "            next_step = least_square_step\n",
    "\n",
    "        (n_samples, n_features) = K.shape\n",
    "        n_kernels = int(n_features/n_samples) # We assume each kernel is a square matrix\n",
    "        self.n_samples, self.n_kernels = n_samples, n_kernels\n",
    "\n",
    "        if Lipschitz_constant==None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(K)\n",
    "\n",
    "        tol = 10**(-6)\n",
    "        coefs_current = np.zeros(n_features, dtype=np.float) # coefficients to compute\n",
    "        coefs_next = np.zeros(n_features, dtype=np.float)\n",
    "        Z = np.copy(coefs_next) # a linear combination of the coefficients of the 2 last iterations\n",
    "        tau_1 = 1\n",
    "\n",
    "        if self.penalty=='l11':\n",
    "            prox = lambda u:prox_l11(u, self.lambda_*Lipschitz_constant)\n",
    "        elif self.penalty=='l22':\n",
    "            prox = lambda u:prox_l22(u, self.lambda_*Lipschitz_constant)\n",
    "        elif self.penalty=='l21':\n",
    "            prox = lambda u:prox_l21(u, self.lambda_*Lipschitz_constant, n_samples, n_kernels)\n",
    "        elif self.penalty=='l12':\n",
    "            prox = lambda u:prox_l12(u, self.lambda_*Lipschitz_constant, n_samples, n_kernels)\n",
    "\n",
    "        if verbose==1:\n",
    "            self.iteration_dual_gap = list()\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            coefs_current = coefs_next # B_(k-1) = B_(k)\n",
    "            coefs_next = prox(Z + Lipschitz_constant*next_step(y, K, Z))\n",
    "            \n",
    "            tau_0 = tau_1 #tau_(k+1) = tau_k\n",
    "            tau_1 = (1 + sqrt(1 + 4*tau_0**2))/2\n",
    "\n",
    "            Z = coefs_next + (tau_0 - 1)/tau_1*(coefs_next - coefs_current)\n",
    "            \n",
    "            # Dual problem\n",
    "            objective_var = 1 - np.dot(K, coefs_next)\n",
    "            objective_var = np.maximum(objective_var, 0) # Shrink\n",
    "            # Primal objective function\n",
    "            penalisation = self.lambda_/self.q*(mixed_norm(coefs_next,\n",
    "                    self.p, self.q, n_samples, n_kernels)**self.q)\n",
    "            loss = 0.5*np.sum(objective_var**2)\n",
    "            objective_function = penalisation + loss\n",
    "\n",
    "            # Dual objective function\n",
    "            dual_var = objective_var\n",
    "            if self.lambda_ != 0:\n",
    "                dual_penalisation = dual_mixed_norm(np.dot(K.T,dual_var)/self.lambda_,\n",
    "                        n_samples, n_kernels, self.penalty)\n",
    "                if self.q==1:\n",
    "                    # Fenchel conjugate of a mixed norm\n",
    "                    if dual_penalisation > 1:\n",
    "                        dual_var = dual_var / dual_penalisation\n",
    "                        # If we did not normalise, dual_penalisation\n",
    "                        # would be +infinity ...\n",
    "                    dual_penalisation = 0\n",
    "                else:\n",
    "                    # Fenchel conjugate of a squared mixed norm\n",
    "                    dual_penalisation = self.lambda_/2*(dual_penalisation**2)\n",
    "            else:\n",
    "                dual_penalisation = 0\n",
    "            dual_loss = -0.5*np.sum(dual_var**2) + np.sum(dual_var)\n",
    "            # trace(np.dot(duat_var[:, np.newaxis], y)) au lieu du sum(dual_var) ?\n",
    "            dual_objective_function = dual_loss - self.lambda_/self.q*dual_penalisation\n",
    "            gap = abs(objective_function - dual_objective_function)\n",
    "\n",
    "            if verbose:\n",
    "                sys.stderr.write(\"Iteration : %d\\r\" % i )\n",
    "                # print \"iteration %d\" % i\n",
    "                self.iteration_dual_gap.append(gap)\n",
    "                if i%1000 == 0:\n",
    "                    print(\"primal objective : %f, dual objective : %f, dual_gap : %f\" % (objective_function, dual_objective_function, gap))\n",
    "\n",
    "            if gap<=tol and i>10:\n",
    "                print(\"convergence at iteration : %d\" %i)\n",
    "                break\n",
    "\n",
    "        if verbose:\n",
    "            print(\"dual gap : %f\" % gap)\n",
    "            print(\"objective_function : %f\" % objective_function)\n",
    "            print(\"dual_objective_function : %f\" % dual_objective_function)\n",
    "            print(\"dual_penalisation : %f\" % dual_penalisation)\n",
    "            print(\"dual_loss : %f\" % dual_loss)\n",
    "        self.coefs_ = coefs_next\n",
    "        self.gap = gap\n",
    "        self.objective_function = objective_function\n",
    "        self.dual_objective_function = dual_objective_function\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, K):\n",
    "        \"\"\" Returns the prediction associated to the Kernels represented by K\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        K : ndarray \n",
    "            ndarray of size (n_samples, n_kernels*n_samples) representing the kernels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to K\n",
    "        \"\"\"\n",
    "        if self.loss=='squared-hinge':\n",
    "            res = np.sign(np.dot(K, self.coefs_))\n",
    "            res[res==0] = 1\n",
    "            return res\n",
    "        else:\n",
    "            return np.dot(K, self.coefs_)\n",
    "\n",
    "    def score(self, K, y):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        K : ndarray\n",
    "            matrix of observations\n",
    "\n",
    "        y : ndarray\n",
    "            the labels correspondings to K\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for K\n",
    "        \"\"\"\n",
    "        if self.loss=='squared-hinge':\n",
    "            return np.sum(np.equal(self.predict(K), y))*100./len(y)\n",
    "        else:\n",
    "            print(\"Score not yet implemented for regression\\n\")\n",
    "            return None\n",
    "\n",
    "    def info(self, K, y):\n",
    "        \"\"\" For test purpose\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        K : 2D-array\n",
    "            kernels\n",
    "\n",
    "        y : ndarray\n",
    "            labels\n",
    "        Returns\n",
    "        -------\n",
    "        A dict of informations\n",
    "        \"\"\"\n",
    "        result = Bunch()\n",
    "        n_samples, n_kernels = self.n_samples, self.n_kernels\n",
    "        nulled_kernels = 0\n",
    "        nulled_coefs_per_kernel = list()\n",
    "\n",
    "        for i in self.coefs_.reshape(n_kernels, n_samples):\n",
    "            if len(i[i!=0]) == 0:\n",
    "                nulled_kernels = nulled_kernels + 1\n",
    "            nulled_coefs_per_kernel.append(len(i[i==0]))\n",
    "\n",
    "        result['score'] = self.score(K, y)\n",
    "        result['norms'] = by_kernel_norm(self.coefs_, self.p, self.q,\n",
    "                n_samples, n_kernels)\n",
    "        result['nulled_coefs'] = len(self.coefs_[self.coefs_==0])\n",
    "        result['nulled_kernels'] = nulled_kernels\n",
    "        result['nulled_coefs_per_kernel'] = nulled_coefs_per_kernel\n",
    "        result['objective_function'] = self.objective_function\n",
    "        result['dual_objective_function'] = self.dual_objective_function\n",
    "        result['gap'] = self.gap\n",
    "        result['auc_score'] = roc_auc_score(y, self.predict(K))\n",
    "        result['lambda_'] = self.lambda_\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device('cuda')\n",
    "#    torch.backends.cudnn.enabled = False\n",
    "#else:\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_padding(list_of_embeddings, length, embedding_length):\n",
    "    zero_vec = np.zeros(embedding_length)\n",
    "    for _ in range(length - len(list_of_embeddings)):\n",
    "        list_of_embeddings.append(zero_vec)\n",
    "    return list_of_embeddings[:length]\n",
    "\n",
    "\n",
    "def word2vec_sum(list_of_embeddings, embedding_length):\n",
    "    ret_value = np.zeros(embedding_length)\n",
    "    for embedding in list_of_embeddings:\n",
    "        ret_value += embedding\n",
    "    return ret_value\n",
    "\n",
    "class OneHotParser(TextParser):\n",
    "    def __init__(self, vocabulary, type_func):\n",
    "        \"\"\"\n",
    "\n",
    "        :param vocabulary: List of strings representing the vocabulary.\n",
    "        :param type_func: Function which converts the output to the desired type, e.g. np.array.\n",
    "        \"\"\"\n",
    "        self.vocab = vocabulary\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        TextParser.__init__(self, type_func)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        one_hot = np.zeros((len(x), self.vocab_size))  # +1 for out of vocabulary tokens.\n",
    "        for idx, token_list in enumerate(x):\n",
    "            sentence = ' '.join(token_list)\n",
    "            vocab_idx = self.vocab.index(sentence)\n",
    "            one_hot[idx, vocab_idx] = 1\n",
    "\n",
    "        return self.convert_type(one_hot)\n",
    "\n",
    "def load_list_from_file(file_path):\n",
    "    with open(file_path) as file:\n",
    "        content = file.readlines()\n",
    "    ret = []\n",
    "    for elem in content:\n",
    "        clean_elem = elem.strip()\n",
    "        if len(clean_elem) > 0:\n",
    "            ret.append(clean_elem)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'full'\n",
    "with open(os.getcwd() + '/data/zork_walkthrough_' + task + '.txt', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "raw_actions = data['actions']\n",
    "raw_states = data['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = ['go', 'take', 'open', 'grab', 'run', 'walk', 'climb', 'kill', 'light', 'get']\n",
    "\n",
    "#basic_actions = ['open', 'egg', 'east', 'west', 'north', 'south', 'go', 'up', 'down', 'look', 'take']\n",
    "basic_actions = ['open', 'egg', 'north', 'climb', 'tree', 'take']\n",
    "\n",
    "extended_actions = ['grab', 'run', 'climb', 'walk', 'go', 'south', 'east', 'west']\n",
    "\n",
    "basic_objects = ['egg', 'door', 'tree', 'leaves', 'nest']\n",
    "\n",
    "obj_ext1 = ['bag', 'bottle', 'rope', 'sword', 'lantern', 'knife', 'mat', 'mailbox',\n",
    "            'rug', 'case', 'axe', 'diamond', 'leaflet', 'news', 'brick']\n",
    "action_ext1 = ['enter', 'open the window', 'turn lamp on', 'move rug', 'open trap door', 'hit troll with sword']\n",
    "\n",
    "random_words = ['bring', 'wait', 'test', 'heave', 'squat', 'garbage', 'you', 'no', 'year']\n",
    "\n",
    "def create_actions():\n",
    "    action_vocabulary = {}\n",
    "    for word in dictionary:\n",
    "        action_vocabulary[word] = word2vec_model[word]\n",
    "\n",
    "    embedding_size = len(action_vocabulary['open'])\n",
    "    \n",
    "    return action_vocabulary, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = glove_api.load('glove-wiki-gigaword-50')\n",
    "embedding_size = word2vec_model.vector_size\n",
    "word2vec_parser = Word2Vec(type_func=lambda x: torch.FloatTensor(x).to(device).unsqueeze(0),\n",
    "                           word2vec_model=word2vec_model,\n",
    "                           return_func=lambda x: word2vec_padding(x, 65, embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fista = Fista(lambda_=0.8, loss='least-square', penalty='l11', n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = ['pray', 'yellow', 'trapdoor', 'open', 'bell', 'touch', 'pile', 'trunk', 'sack', 'inflate', 'southeast',\n",
    "              'of', 'move', 'match', 'figurine', 'railing', 'with', 'map', 'mirror', 'wind', 'examine', 'north', 'out',\n",
    "              'trident', 'turn', 'skull', 'throw', 'northwest', 'case', 'bag', 'red', 'press', 'jewels', 'east', 'pump',\n",
    "              'bolt', 'rusty', 'window', 'douse', 'boat', 'bracelet', 'matchbook', 'basket', 'book', 'coffin', 'bar',\n",
    "              'rug', 'lid', 'drop', 'nasty', 'wrench', 'light', 'sand', 'bauble', 'kill', 'tie', 'painting', 'sword',\n",
    "              'wave', 'in', 'south', 'northeast', 'ring', 'canary', 'lower', 'egg', 'all', 'to', 'candles', 'page',\n",
    "              'and', 'echo', 'emerald', 'tree', 'from', 'rope', 'troll', 'screwdriver', 'torch', 'enter', 'coal', 'go',\n",
    "              'look', 'shovel', 'knife', 'down', 'take', 'switch', 'prayer', 'launch', 'diamond', 'read', 'up', 'get',\n",
    "              'scarab', 'west', 'land', 'southwest', 'climb', 'thief', 'raise', 'wait', 'odysseus', 'button', 'sceptre',\n",
    "              'lamp', 'chalice', 'garlic', 'buoy', 'pot', 'label', 'put', 'dig', 'machine', 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = MultivariateNormal(torch.zeros(50), torch.eye(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(additional_prints, threshold, snr, its):\n",
    "    runs = []\n",
    "    for _ in range(its):\n",
    "        accurate = 0\n",
    "        for action in raw_actions:\n",
    "            vec = 0\n",
    "            for token in tokenizer(action):\n",
    "                vec += word2vec_model[token]\n",
    "\n",
    "            sampled_noise = noise.sample().numpy()\n",
    "            normalized_noise = snr * np.linalg.norm(vec) * sampled_noise / np.linalg.norm(sampled_noise)            \n",
    "            ground_truth = torch.Tensor(vec + normalized_noise).to(device).unsqueeze(0)\n",
    "\n",
    "            deepcs_output = network(ground_truth, True).squeeze(0)\n",
    "            list_of_words = []\n",
    "            for idx in range(len(deepcs_output)):\n",
    "                if deepcs_output[idx] > threshold:\n",
    "                    list_of_words.append(idx)\n",
    "\n",
    "            _, text_command = agent._select_eps_greedy_action(0, list_of_words, None)\n",
    "\n",
    "            if set(tokenizer(action)) == set(tokenizer(text_command)):\n",
    "                accurate += 1\n",
    "            elif additional_prints:\n",
    "                print(tokenizer(text_command))\n",
    "                print(tokenizer(action))\n",
    "\n",
    "        runs.append(accurate * 1.0 / len(raw_actions))\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(additional_prints, threshold, snr, its, seed=52):\n",
    "    with torch.no_grad():\n",
    "        runs = []\n",
    "        for _ in range(its):\n",
    "            obs = agent.env.reset(seed)\n",
    "            reward = 0\n",
    "            done = False\n",
    "\n",
    "            idx = 0\n",
    "            for action in raw_actions:\n",
    "                vec = 0\n",
    "                for token in tokenizer(action):\n",
    "                    vec += word2vec_model[token]\n",
    "\n",
    "                sampled_noise = noise.sample().numpy()\n",
    "                normalized_noise = snr * np.linalg.norm(vec) * sampled_noise / np.linalg.norm(sampled_noise)            \n",
    "                ground_truth = torch.Tensor(vec + normalized_noise).to(device).unsqueeze(0)\n",
    "\n",
    "                deepcs_output = network(ground_truth, True).squeeze(0)\n",
    "                list_of_words = []\n",
    "                for idx in range(len(deepcs_output)):\n",
    "                    if deepcs_output[idx] > threshold:\n",
    "                        list_of_words.append(idx)\n",
    "\n",
    "                _, text_command = agent._select_eps_greedy_action(0, list_of_words, None)\n",
    "\n",
    "                if additional_prints:\n",
    "                    agent.env.render()\n",
    "                    print(text_command)\n",
    "                idx += 1\n",
    "                obs, rew, done, has_won = agent.env.step(text_command)\n",
    "                if additional_prints:\n",
    "                    print(rew)\n",
    "                reward += rew\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            runs.append(int(agent.env.env.get_score()))\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_neighbors=5\n",
    "\n",
    "action_vocabulary, embedding_size = create_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OMPDDPG(actions=action_vocabulary,\n",
    "                state_parser=word2vec_parser,\n",
    "                embedding_size=embedding_size,\n",
    "                input_length=embedding_size,\n",
    "                input_width=65,\n",
    "                history_size=12,\n",
    "                model_type='CNN',\n",
    "                device=device,\n",
    "                pomdp_mode=False,\n",
    "                loss_weighting=1.0,\n",
    "                linear=False,\n",
    "                improved_omp=False,\n",
    "                task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.env.sparse_reward = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/deep_cs_' + task + '_cs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBow(nn.Module):\n",
    "    def __init__(self, embedding_size, output_size, hidden_layers):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        self.linears.append(nn.Linear(embedding_size, hidden_layers[0]))\n",
    "        for idx in range(len(hidden_layers) - 1):\n",
    "            self.linears.append(nn.Linear(hidden_layers[idx], hidden_layers[idx + 1]))\n",
    "\n",
    "        self.linears.append(nn.Linear(hidden_layers[-1], output_size))\n",
    "\n",
    "    def forward(self, x, sigmoid=False):\n",
    "        x_relu = x.view(x.size(0), -1)\n",
    "        for idx in range(len(self.linears)):\n",
    "            x = self.linears[idx](x_relu)\n",
    "            x_relu = F.relu(x)\n",
    "        if sigmoid:\n",
    "            return F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MlpBow(embedding_size, len(dictionary), [100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results for safe keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_accuracy = {0.3: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.9754299754299754, 0.9656019656019657, 0.9508599508599509, 0.9656019656019657, 0.9606879606879607, 0.972972972972973, 0.9680589680589681, 0.9705159705159705, 0.9631449631449631, 0.9803439803439803, 0.9582309582309583, 0.9631449631449631, 0.9631449631449631, 0.9680589680589681, 0.9705159705159705, 0.9656019656019657, 0.9582309582309583, 0.9705159705159705, 0.9656019656019657, 0.972972972972973, 0.9705159705159705, 0.9705159705159705, 0.972972972972973, 0.9606879606879607, 0.9606879606879607, 0.9754299754299754, 0.972972972972973, 0.9656019656019657, 0.9631449631449631, 0.9631449631449631, 0.9631449631449631, 0.972972972972973, 0.9705159705159705, 0.9606879606879607, 0.9778869778869779, 0.9631449631449631, 0.9557739557739557, 0.9631449631449631, 0.9656019656019657, 0.9656019656019657, 0.9533169533169533, 0.9557739557739557, 0.972972972972973, 0.9852579852579852, 0.9680589680589681, 0.9803439803439803, 0.9754299754299754, 0.9680589680589681, 0.9656019656019657, 0.9803439803439803, 0.972972972972973, 0.9705159705159705, 0.9606879606879607, 0.9631449631449631, 0.972972972972973, 0.9828009828009828, 0.9778869778869779, 0.9656019656019657, 0.9705159705159705, 0.9754299754299754, 0.9606879606879607, 0.9631449631449631, 0.9778869778869779, 0.9754299754299754, 0.9705159705159705, 0.9606879606879607, 0.9680589680589681, 0.9582309582309583, 0.9656019656019657, 0.9631449631449631, 0.9582309582309583, 0.9631449631449631, 0.9631449631449631, 0.9680589680589681, 0.9582309582309583, 0.9705159705159705, 0.9606879606879607, 0.9606879606879607, 0.9754299754299754, 0.9852579852579852], 0.4: [0.8132678132678133, 0.7518427518427518, 0.7395577395577395, 0.7936117936117936, 0.7272727272727273, 0.7321867321867321, 0.7665847665847666, 0.7346437346437347, 0.7518427518427518, 0.7223587223587223, 0.769041769041769, 0.7641277641277642, 0.7714987714987716, 0.7395577395577395, 0.7592137592137592, 0.7936117936117936, 0.7813267813267813, 0.7714987714987716, 0.7788697788697788, 0.7641277641277642, 0.773955773955774, 0.7518427518427518, 0.7469287469287469, 0.7641277641277642, 0.7764127764127764, 0.7911547911547911, 0.773955773955774, 0.7371007371007371, 0.7518427518427518, 0.7567567567567568, 0.7542997542997543, 0.7764127764127764, 0.773955773955774, 0.7444717444717445, 0.7272727272727273, 0.769041769041769, 0.7371007371007371, 0.7911547911547911, 0.7542997542997543, 0.7641277641277642, 0.7985257985257985, 0.8058968058968059, 0.7542997542997543, 0.7542997542997543, 0.8034398034398035, 0.773955773955774, 0.7788697788697788, 0.773955773955774, 0.8108108108108109, 0.7518427518427518, 0.7788697788697788, 0.8329238329238329, 0.7542997542997543, 0.7862407862407862, 0.7641277641277642, 0.7837837837837838, 0.7518427518427518, 0.7960687960687961, 0.7567567567567568, 0.8083538083538083, 0.7714987714987716, 0.7837837837837838, 0.7567567567567568, 0.714987714987715, 0.7641277641277642, 0.7199017199017199, 0.7714987714987716, 0.7395577395577395, 0.7567567567567568, 0.7321867321867321, 0.7518427518427518, 0.7297297297297297, 0.7764127764127764, 0.7542997542997543, 0.7444717444717445, 0.773955773955774, 0.7297297297297297, 0.7321867321867321, 0.7444717444717445, 0.7788697788697788], 0.6: [0.5233415233415234, 0.5036855036855037, 0.515970515970516, 0.542997542997543, 0.5282555282555282, 0.5085995085995086, 0.5135135135135135, 0.5208845208845209, 0.5307125307125307, 0.47665847665847666, 0.5135135135135135, 0.5208845208845209, 0.5405405405405406, 0.5626535626535627, 0.5282555282555282, 0.538083538083538, 0.515970515970516, 0.5036855036855037, 0.5307125307125307, 0.5233415233415234, 0.49385749385749383, 0.47174447174447176, 0.5331695331695332, 0.5331695331695332, 0.5257985257985258, 0.5110565110565111, 0.515970515970516, 0.5110565110565111, 0.542997542997543, 0.5331695331695332, 0.5282555282555282, 0.547911547911548, 0.457002457002457, 0.515970515970516, 0.48894348894348894, 0.4914004914004914, 0.5282555282555282, 0.4963144963144963, 0.4594594594594595, 0.547911547911548, 0.48894348894348894, 0.5208845208845209, 0.5307125307125307, 0.5700245700245701, 0.515970515970516, 0.547911547911548, 0.542997542997543, 0.5307125307125307, 0.5356265356265356, 0.515970515970516, 0.5503685503685504, 0.5601965601965602, 0.5184275184275184, 0.5307125307125307, 0.4914004914004914, 0.5724815724815725, 0.4742014742014742, 0.5773955773955773, 0.5282555282555282, 0.5331695331695332, 0.47911547911547914, 0.515970515970516, 0.4619164619164619, 0.4692874692874693, 0.5135135135135135, 0.4692874692874693, 0.5135135135135135, 0.542997542997543, 0.48402948402948404, 0.48894348894348894, 0.4668304668304668, 0.44717444717444715, 0.5012285012285013, 0.48157248157248156, 0.538083538083538, 0.5012285012285013, 0.48402948402948404, 0.515970515970516, 0.5085995085995086, 0.4643734643734644], 0.8: [0.35626535626535627, 0.3832923832923833, 0.371007371007371, 0.36855036855036855, 0.39803439803439805, 0.3759213759213759, 0.3955773955773956, 0.3832923832923833, 0.3046683046683047, 0.3366093366093366, 0.3832923832923833, 0.36609336609336607, 0.3046683046683047, 0.35626535626535627, 0.371007371007371, 0.31695331695331697, 0.3538083538083538, 0.36363636363636365, 0.32186732186732187, 0.3366093366093366, 0.3464373464373464, 0.3366093366093366, 0.3415233415233415, 0.35135135135135137, 0.35872235872235875, 0.3955773955773956, 0.3857493857493858, 0.32923832923832924, 0.36609336609336607, 0.3316953316953317, 0.343980343980344, 0.35872235872235875, 0.35135135135135137, 0.32678132678132676, 0.36855036855036855, 0.3464373464373464, 0.33906633906633904, 0.3316953316953317, 0.37346437346437344, 0.3488943488943489, 0.36363636363636365, 0.35872235872235875, 0.36609336609336607, 0.3538083538083538, 0.36363636363636365, 0.35626535626535627, 0.343980343980344, 0.3415233415233415, 0.35872235872235875, 0.371007371007371, 0.35626535626535627, 0.3366093366093366, 0.3783783783783784, 0.35626535626535627, 0.33415233415233414, 0.343980343980344, 0.3783783783783784, 0.36609336609336607, 0.3538083538083538, 0.35626535626535627, 0.29975429975429974, 0.3488943488943489, 0.33906633906633904, 0.32923832923832924, 0.3464373464373464, 0.36855036855036855, 0.3808353808353808, 0.3316953316953317, 0.3095823095823096, 0.33415233415233414, 0.3415233415233415, 0.3488943488943489, 0.28746928746928746, 0.3194103194103194, 0.3046683046683047, 0.32923832923832924, 0.35135135135135137, 0.28746928746928746, 0.31695331695331697, 0.25552825552825553], 1.0: [0.23587223587223588, 0.2285012285012285, 0.2628992628992629, 0.2678132678132678, 0.2628992628992629, 0.23587223587223588, 0.2727272727272727, 0.25061425061425063, 0.23587223587223588, 0.24324324324324326, 0.22358722358722358, 0.25061425061425063, 0.2678132678132678, 0.24324324324324326, 0.24815724815724816, 0.23587223587223588, 0.2628992628992629, 0.2800982800982801, 0.2457002457002457, 0.2727272727272727, 0.2457002457002457, 0.26535626535626533, 0.24324324324324326, 0.2727272727272727, 0.26044226044226043, 0.23095823095823095, 0.2800982800982801, 0.23095823095823095, 0.23587223587223588, 0.25061425061425063, 0.22604422604422605, 0.24815724815724816, 0.24324324324324326, 0.24324324324324326, 0.24324324324324326, 0.2457002457002457, 0.2334152334152334, 0.22113022113022113, 0.22358722358722358, 0.22358722358722358, 0.28501228501228504, 0.23587223587223588, 0.25552825552825553, 0.257985257985258, 0.2334152334152334, 0.25307125307125306, 0.26044226044226043, 0.24078624078624078, 0.28746928746928746, 0.28255528255528256, 0.2628992628992629, 0.26044226044226043, 0.2727272727272727, 0.25307125307125306, 0.25307125307125306, 0.25307125307125306, 0.21621621621621623, 0.2727272727272727, 0.26044226044226043, 0.24078624078624078, 0.22358722358722358, 0.22604422604422605, 0.2457002457002457, 0.2457002457002457, 0.23587223587223588, 0.25061425061425063, 0.23587223587223588, 0.25552825552825553, 0.20638820638820637, 0.21375921375921375, 0.21867321867321868, 0.21867321867321868, 0.21375921375921375, 0.22604422604422605, 0.21867321867321868, 0.21867321867321868, 0.22604422604422605, 0.22358722358722358, 0.19656019656019655, 0.20393120393120392]}, 0.5: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.9631449631449631, 0.9606879606879607, 0.9754299754299754, 0.9606879606879607, 0.9680589680589681, 0.9705159705159705, 0.9877149877149877, 0.9680589680589681, 0.9803439803439803, 0.9680589680589681, 0.9803439803439803, 0.9680589680589681, 0.9754299754299754, 0.9705159705159705, 0.9852579852579852, 0.9852579852579852, 0.9926289926289926, 0.972972972972973, 0.9680589680589681, 0.9606879606879607, 0.9803439803439803, 0.9680589680589681, 0.9656019656019657, 0.972972972972973, 0.972972972972973, 0.9778869778869779, 0.9705159705159705, 0.9656019656019657, 0.9705159705159705, 0.9582309582309583, 0.9705159705159705, 0.9754299754299754, 0.9803439803439803, 0.9557739557739557, 0.972972972972973, 0.972972972972973, 0.9754299754299754, 0.9631449631449631, 0.9754299754299754, 0.9680589680589681, 0.9778869778869779, 0.9631449631449631, 0.9656019656019657, 0.9582309582309583, 0.9656019656019657, 0.9754299754299754, 0.9680589680589681, 0.9778869778869779, 0.972972972972973, 0.9778869778869779, 0.9778869778869779, 0.9606879606879607, 0.9606879606879607, 0.9754299754299754, 0.9705159705159705, 0.9705159705159705, 0.9803439803439803, 0.9705159705159705, 0.9705159705159705, 0.9778869778869779, 0.972972972972973, 0.9852579852579852, 0.972972972972973, 0.9582309582309583, 0.9778869778869779, 0.9582309582309583, 0.9606879606879607, 0.9705159705159705, 0.9680589680589681, 0.9754299754299754, 0.972972972972973, 0.9656019656019657, 0.9631449631449631, 0.9754299754299754, 0.9582309582309583, 0.9606879606879607, 0.9631449631449631, 0.9582309582309583, 0.9656019656019657, 0.9606879606879607], 0.4: [0.773955773955774, 0.7395577395577395, 0.7714987714987716, 0.7641277641277642, 0.7641277641277642, 0.7469287469287469, 0.7764127764127764, 0.769041769041769, 0.7518427518427518, 0.7764127764127764, 0.7641277641277642, 0.8034398034398035, 0.7272727272727273, 0.742014742014742, 0.7788697788697788, 0.742014742014742, 0.742014742014742, 0.7567567567567568, 0.7469287469287469, 0.7641277641277642, 0.769041769041769, 0.7493857493857494, 0.7542997542997543, 0.769041769041769, 0.7714987714987716, 0.7567567567567568, 0.7469287469287469, 0.7837837837837838, 0.7444717444717445, 0.7813267813267813, 0.7862407862407862, 0.7592137592137592, 0.7592137592137592, 0.7911547911547911, 0.7665847665847666, 0.7567567567567568, 0.7764127764127764, 0.7862407862407862, 0.7886977886977887, 0.7371007371007371, 0.773955773955774, 0.773955773955774, 0.7813267813267813, 0.7493857493857494, 0.769041769041769, 0.773955773955774, 0.7788697788697788, 0.7469287469287469, 0.7714987714987716, 0.8108108108108109, 0.7837837837837838, 0.7493857493857494, 0.7616707616707616, 0.7714987714987716, 0.7371007371007371, 0.7837837837837838, 0.7493857493857494, 0.8108108108108109, 0.769041769041769, 0.7837837837837838, 0.7493857493857494, 0.7444717444717445, 0.7321867321867321, 0.7592137592137592, 0.742014742014742, 0.7567567567567568, 0.769041769041769, 0.7616707616707616, 0.7518427518427518, 0.7297297297297297, 0.7174447174447175, 0.7542997542997543, 0.7346437346437347, 0.7469287469287469, 0.7100737100737101, 0.7518427518427518, 0.7469287469287469, 0.7100737100737101, 0.7248157248157249, 0.7223587223587223], 0.6: [0.5454545454545454, 0.5282555282555282, 0.5085995085995086, 0.5626535626535627, 0.5331695331695332, 0.5528255528255528, 0.5061425061425061, 0.5036855036855037, 0.538083538083538, 0.5307125307125307, 0.5184275184275184, 0.538083538083538, 0.5061425061425061, 0.5012285012285013, 0.5307125307125307, 0.5085995085995086, 0.4963144963144963, 0.515970515970516, 0.5552825552825553, 0.48402948402948404, 0.5135135135135135, 0.5528255528255528, 0.5233415233415234, 0.538083538083538, 0.5012285012285013, 0.5257985257985258, 0.5503685503685504, 0.5085995085995086, 0.5454545454545454, 0.5012285012285013, 0.547911547911548, 0.5233415233415234, 0.5528255528255528, 0.4987714987714988, 0.5405405405405406, 0.5528255528255528, 0.47665847665847666, 0.5823095823095823, 0.48894348894348894, 0.5184275184275184, 0.5184275184275184, 0.5405405405405406, 0.5577395577395577, 0.5626535626535627, 0.47665847665847666, 0.5773955773955773, 0.5454545454545454, 0.5184275184275184, 0.5405405405405406, 0.515970515970516, 0.5503685503685504, 0.5061425061425061, 0.5454545454545454, 0.47911547911547914, 0.5282555282555282, 0.5282555282555282, 0.5331695331695332, 0.5184275184275184, 0.5085995085995086, 0.5012285012285013, 0.5085995085995086, 0.5208845208845209, 0.47174447174447176, 0.4987714987714988, 0.4643734643734644, 0.4963144963144963, 0.5085995085995086, 0.4914004914004914, 0.4643734643734644, 0.4864864864864865, 0.5208845208845209, 0.538083538083538, 0.5233415233415234, 0.48157248157248156, 0.515970515970516, 0.5110565110565111, 0.49385749385749383, 0.5110565110565111, 0.5061425061425061, 0.515970515970516], 0.8: [0.343980343980344, 0.3808353808353808, 0.32923832923832924, 0.32678132678132676, 0.3366093366093366, 0.3783783783783784, 0.35135135135135137, 0.3857493857493858, 0.3464373464373464, 0.36117936117936117, 0.3759213759213759, 0.35626535626535627, 0.3464373464373464, 0.37346437346437344, 0.3538083538083538, 0.3488943488943489, 0.3194103194103194, 0.35626535626535627, 0.36855036855036855, 0.41277641277641275, 0.3488943488943489, 0.3488943488943489, 0.3464373464373464, 0.3366093366093366, 0.36609336609336607, 0.35872235872235875, 0.36363636363636365, 0.35135135135135137, 0.4004914004914005, 0.3316953316953317, 0.4004914004914005, 0.3857493857493858, 0.35135135135135137, 0.35626535626535627, 0.36117936117936117, 0.3194103194103194, 0.32186732186732187, 0.371007371007371, 0.3095823095823096, 0.4103194103194103, 0.3415233415233415, 0.3488943488943489, 0.3464373464373464, 0.36117936117936117, 0.3464373464373464, 0.36609336609336607, 0.3808353808353808, 0.31695331695331697, 0.37346437346437344, 0.36855036855036855, 0.343980343980344, 0.371007371007371, 0.3783783783783784, 0.3488943488943489, 0.32923832923832924, 0.3464373464373464, 0.3832923832923833, 0.3415233415233415, 0.3464373464373464, 0.36609336609336607, 0.3071253071253071, 0.3366093366093366, 0.3316953316953317, 0.33906633906633904, 0.343980343980344, 0.32923832923832924, 0.36117936117936117, 0.27764127764127766, 0.3316953316953317, 0.32678132678132676, 0.32432432432432434, 0.3415233415233415, 0.32432432432432434, 0.3071253071253071, 0.33415233415233414, 0.3144963144963145, 0.371007371007371, 0.3194103194103194, 0.343980343980344, 0.3488943488943489], 1.0: [0.2113022113022113, 0.23587223587223588, 0.2727272727272727, 0.257985257985258, 0.21375921375921375, 0.28255528255528256, 0.2334152334152334, 0.257985257985258, 0.257985257985258, 0.24078624078624078, 0.23587223587223588, 0.25061425061425063, 0.26535626535626533, 0.2334152334152334, 0.25552825552825553, 0.2678132678132678, 0.28255528255528256, 0.26044226044226043, 0.22113022113022113, 0.28746928746928746, 0.2678132678132678, 0.24815724815724816, 0.2628992628992629, 0.2628992628992629, 0.2702702702702703, 0.23095823095823095, 0.2334152334152334, 0.257985257985258, 0.26044226044226043, 0.20884520884520885, 0.22113022113022113, 0.2334152334152334, 0.24324324324324326, 0.25061425061425063, 0.23587223587223588, 0.25307125307125306, 0.21621621621621623, 0.2702702702702703, 0.23587223587223588, 0.23587223587223588, 0.23832923832923833, 0.25307125307125306, 0.25552825552825553, 0.26044226044226043, 0.24815724815724816, 0.24815724815724816, 0.20147420147420148, 0.21867321867321868, 0.25061425061425063, 0.257985257985258, 0.25307125307125306, 0.2678132678132678, 0.257985257985258, 0.2800982800982801, 0.22113022113022113, 0.25061425061425063, 0.2727272727272727, 0.257985257985258, 0.25061425061425063, 0.24324324324324326, 0.22358722358722358, 0.24078624078624078, 0.21867321867321868, 0.24324324324324326, 0.26535626535626533, 0.25552825552825553, 0.20884520884520885, 0.25061425061425063, 0.23832923832923833, 0.22358722358722358, 0.26044226044226043, 0.2678132678132678, 0.24815724815724816, 0.23832923832923833, 0.19656019656019655, 0.2457002457002457, 0.24324324324324326, 0.25552825552825553, 0.22358722358722358, 0.2457002457002457]}, 0.7: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.9680589680589681, 0.9557739557739557, 0.9631449631449631, 0.9705159705159705, 0.9631449631449631, 0.9606879606879607, 0.9680589680589681, 0.9778869778869779, 0.9680589680589681, 0.9533169533169533, 0.9705159705159705, 0.9606879606879607, 0.9631449631449631, 0.9631449631449631, 0.9631449631449631, 0.9852579852579852, 0.972972972972973, 0.9680589680589681, 0.972972972972973, 0.9778869778869779, 0.9705159705159705, 0.9680589680589681, 0.9656019656019657, 0.9582309582309583, 0.9557739557739557, 0.972972972972973, 0.9656019656019657, 0.9606879606879607, 0.972972972972973, 0.9754299754299754, 0.9533169533169533, 0.9582309582309583, 0.972972972972973, 0.972972972972973, 0.9631449631449631, 0.9680589680589681, 0.9803439803439803, 0.9582309582309583, 0.9778869778869779, 0.9705159705159705, 0.9680589680589681, 0.9582309582309583, 0.9582309582309583, 0.9778869778869779, 0.9705159705159705, 0.9680589680589681, 0.9582309582309583, 0.9705159705159705, 0.972972972972973, 0.972972972972973, 0.9778869778869779, 0.9803439803439803, 0.9705159705159705, 0.972972972972973, 0.9828009828009828, 0.9705159705159705, 0.9705159705159705, 0.9557739557739557, 0.972972972972973, 0.9582309582309583, 0.9803439803439803, 0.9631449631449631, 0.9631449631449631, 0.9533169533169533, 0.9606879606879607, 0.9582309582309583, 0.9557739557739557, 0.9508599508599509, 0.9606879606879607, 0.9631449631449631, 0.9557739557739557, 0.9656019656019657, 0.9434889434889435, 0.9631449631449631, 0.9606879606879607, 0.9656019656019657, 0.9778869778869779, 0.972972972972973, 0.972972972972973, 0.9606879606879607], 0.4: [0.7518427518427518, 0.7592137592137592, 0.7469287469287469, 0.769041769041769, 0.7764127764127764, 0.7592137592137592, 0.7248157248157249, 0.7641277641277642, 0.7936117936117936, 0.7518427518427518, 0.7764127764127764, 0.7346437346437347, 0.7567567567567568, 0.773955773955774, 0.7542997542997543, 0.7395577395577395, 0.769041769041769, 0.773955773955774, 0.7788697788697788, 0.7960687960687961, 0.7567567567567568, 0.773955773955774, 0.7444717444717445, 0.7567567567567568, 0.7469287469287469, 0.769041769041769, 0.7714987714987716, 0.7469287469287469, 0.7542997542997543, 0.7837837837837838, 0.7321867321867321, 0.7788697788697788, 0.7714987714987716, 0.7862407862407862, 0.7592137592137592, 0.7641277641277642, 0.7542997542997543, 0.7665847665847666, 0.7444717444717445, 0.7764127764127764, 0.7567567567567568, 0.7444717444717445, 0.7665847665847666, 0.7764127764127764, 0.7665847665847666, 0.8034398034398035, 0.7518427518427518, 0.8034398034398035, 0.7764127764127764, 0.769041769041769, 0.7886977886977887, 0.7764127764127764, 0.7936117936117936, 0.7936117936117936, 0.7714987714987716, 0.7542997542997543, 0.7862407862407862, 0.7641277641277642, 0.769041769041769, 0.7788697788697788, 0.7223587223587223, 0.7174447174447175, 0.7518427518427518, 0.7518427518427518, 0.7321867321867321, 0.7592137592137592, 0.7321867321867321, 0.7444717444717445, 0.7346437346437347, 0.7297297297297297, 0.7641277641277642, 0.7272727272727273, 0.7100737100737101, 0.7616707616707616, 0.7395577395577395, 0.7321867321867321, 0.7469287469287469, 0.7297297297297297, 0.7444717444717445, 0.7444717444717445], 0.6: [0.5110565110565111, 0.5307125307125307, 0.5528255528255528, 0.5626535626535627, 0.515970515970516, 0.5503685503685504, 0.5577395577395577, 0.5233415233415234, 0.5257985257985258, 0.5233415233415234, 0.515970515970516, 0.4864864864864865, 0.5110565110565111, 0.5749385749385749, 0.538083538083538, 0.5233415233415234, 0.5135135135135135, 0.5282555282555282, 0.4963144963144963, 0.547911547911548, 0.5577395577395577, 0.5208845208845209, 0.5405405405405406, 0.5208845208845209, 0.538083538083538, 0.542997542997543, 0.5331695331695332, 0.5233415233415234, 0.5503685503685504, 0.5405405405405406, 0.5233415233415234, 0.515970515970516, 0.5282555282555282, 0.5233415233415234, 0.5282555282555282, 0.6044226044226044, 0.5233415233415234, 0.5233415233415234, 0.5135135135135135, 0.5307125307125307, 0.5773955773955773, 0.5405405405405406, 0.5749385749385749, 0.5061425061425061, 0.5823095823095823, 0.49385749385749383, 0.542997542997543, 0.5331695331695332, 0.5552825552825553, 0.5405405405405406, 0.5307125307125307, 0.5307125307125307, 0.5503685503685504, 0.5724815724815725, 0.5528255528255528, 0.5307125307125307, 0.5626535626535627, 0.5552825552825553, 0.5307125307125307, 0.5331695331695332, 0.4987714987714988, 0.4643734643734644, 0.5135135135135135, 0.5036855036855037, 0.5208845208845209, 0.4987714987714988, 0.5012285012285013, 0.49385749385749383, 0.5282555282555282, 0.4668304668304668, 0.4742014742014742, 0.5135135135135135, 0.4668304668304668, 0.5208845208845209, 0.5061425061425061, 0.4864864864864865, 0.47665847665847666, 0.5233415233415234, 0.47911547911547914, 0.47911547911547914], 0.8: [0.3783783783783784, 0.36609336609336607, 0.35626535626535627, 0.3906633906633907, 0.3955773955773956, 0.3857493857493858, 0.3464373464373464, 0.33415233415233414, 0.371007371007371, 0.3488943488943489, 0.3488943488943489, 0.35135135135135137, 0.35135135135135137, 0.31695331695331697, 0.3906633906633907, 0.36855036855036855, 0.35872235872235875, 0.35872235872235875, 0.4004914004914005, 0.36609336609336607, 0.40786240786240785, 0.35872235872235875, 0.35135135135135137, 0.3906633906633907, 0.33906633906633904, 0.32923832923832924, 0.36363636363636365, 0.36363636363636365, 0.36363636363636365, 0.3783783783783784, 0.35135135135135137, 0.3906633906633907, 0.3857493857493858, 0.31695331695331697, 0.36609336609336607, 0.3808353808353808, 0.35135135135135137, 0.3488943488943489, 0.3783783783783784, 0.32186732186732187, 0.35872235872235875, 0.39803439803439805, 0.3538083538083538, 0.3759213759213759, 0.3783783783783784, 0.3783783783783784, 0.3906633906633907, 0.3783783783783784, 0.3955773955773956, 0.3955773955773956, 0.36117936117936117, 0.36363636363636365, 0.32923832923832924, 0.36609336609336607, 0.32923832923832924, 0.33415233415233414, 0.39803439803439805, 0.37346437346437344, 0.33415233415233414, 0.3464373464373464, 0.3316953316953317, 0.35872235872235875, 0.32186732186732187, 0.3832923832923833, 0.3538083538083538, 0.33906633906633904, 0.3488943488943489, 0.3759213759213759, 0.31203931203931207, 0.28992628992628994, 0.3194103194103194, 0.33415233415233414, 0.32678132678132676, 0.31695331695331697, 0.3095823095823096, 0.3366093366093366, 0.36117936117936117, 0.37346437346437344, 0.3415233415233415, 0.32923832923832924], 1.0: [0.2628992628992629, 0.2628992628992629, 0.2628992628992629, 0.2702702702702703, 0.26044226044226043, 0.2457002457002457, 0.257985257985258, 0.28992628992628994, 0.24078624078624078, 0.2334152334152334, 0.24324324324324326, 0.24815724815724816, 0.22604422604422605, 0.28992628992628994, 0.25307125307125306, 0.257985257985258, 0.257985257985258, 0.3071253071253071, 0.2702702702702703, 0.2285012285012285, 0.24815724815724816, 0.26044226044226043, 0.2727272727272727, 0.20393120393120392, 0.2628992628992629, 0.28746928746928746, 0.26535626535626533, 0.2727272727272727, 0.28501228501228504, 0.25061425061425063, 0.26535626535626533, 0.257985257985258, 0.2702702702702703, 0.257985257985258, 0.27764127764127766, 0.31695331695331697, 0.25307125307125306, 0.2334152334152334, 0.23832923832923833, 0.22604422604422605, 0.29975429975429974, 0.2727272727272727, 0.25307125307125306, 0.28746928746928746, 0.26535626535626533, 0.24324324324324326, 0.27764127764127766, 0.2751842751842752, 0.26044226044226043, 0.2751842751842752, 0.28992628992628994, 0.2800982800982801, 0.25307125307125306, 0.2727272727272727, 0.23095823095823095, 0.24078624078624078, 0.25552825552825553, 0.2800982800982801, 0.2727272727272727, 0.2800982800982801, 0.22604422604422605, 0.21867321867321868, 0.26044226044226043, 0.22604422604422605, 0.25552825552825553, 0.21867321867321868, 0.23095823095823095, 0.23095823095823095, 0.2113022113022113, 0.24078624078624078, 0.2334152334152334, 0.25061425061425063, 0.2457002457002457, 0.2702702702702703, 0.23832923832923833, 0.26044226044226043, 0.257985257985258, 0.23095823095823095, 0.24078624078624078, 0.2727272727272727]}, 0.9: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.941031941031941, 0.9557739557739557, 0.9336609336609336, 0.9533169533169533, 0.9606879606879607, 0.9582309582309583, 0.9533169533169533, 0.9459459459459459, 0.9606879606879607, 0.9582309582309583, 0.9680589680589681, 0.9533169533169533, 0.9705159705159705, 0.9508599508599509, 0.9484029484029484, 0.9656019656019657, 0.9533169533169533, 0.9533169533169533, 0.9484029484029484, 0.9705159705159705, 0.9582309582309583, 0.9533169533169533, 0.9582309582309583, 0.9582309582309583, 0.9459459459459459, 0.9508599508599509, 0.941031941031941, 0.9557739557739557, 0.9631449631449631, 0.9557739557739557, 0.9606879606879607, 0.9778869778869779, 0.9533169533169533, 0.9508599508599509, 0.9557739557739557, 0.941031941031941, 0.9557739557739557, 0.9533169533169533, 0.9434889434889435, 0.9656019656019657, 0.9705159705159705, 0.9434889434889435, 0.9582309582309583, 0.9582309582309583, 0.9459459459459459, 0.9582309582309583, 0.9631449631449631, 0.9754299754299754, 0.9606879606879607, 0.9533169533169533, 0.9606879606879607, 0.9631449631449631, 0.9606879606879607, 0.9557739557739557, 0.9754299754299754, 0.9557739557739557, 0.9606879606879607, 0.9656019656019657, 0.9656019656019657, 0.941031941031941, 0.9459459459459459, 0.9484029484029484, 0.9459459459459459, 0.9312039312039312, 0.9508599508599509, 0.9459459459459459, 0.9606879606879607, 0.9336609336609336, 0.9508599508599509, 0.9459459459459459, 0.9582309582309583, 0.9582309582309583, 0.9459459459459459, 0.9533169533169533, 0.9508599508599509, 0.9754299754299754, 0.9434889434889435, 0.9533169533169533, 0.9557739557739557, 0.9508599508599509], 0.4: [0.7444717444717445, 0.7076167076167076, 0.773955773955774, 0.7321867321867321, 0.7567567567567568, 0.7616707616707616, 0.7592137592137592, 0.7567567567567568, 0.7567567567567568, 0.7616707616707616, 0.7223587223587223, 0.7199017199017199, 0.7125307125307125, 0.7297297297297297, 0.7346437346437347, 0.7395577395577395, 0.7297297297297297, 0.7174447174447175, 0.7321867321867321, 0.7174447174447175, 0.7395577395577395, 0.7051597051597052, 0.7469287469287469, 0.6928746928746928, 0.7248157248157249, 0.7395577395577395, 0.6928746928746928, 0.7051597051597052, 0.7174447174447175, 0.7567567567567568, 0.742014742014742, 0.7371007371007371, 0.7174447174447175, 0.7321867321867321, 0.7100737100737101, 0.742014742014742, 0.742014742014742, 0.7125307125307125, 0.7297297297297297, 0.7248157248157249, 0.7223587223587223, 0.7395577395577395, 0.7395577395577395, 0.7567567567567568, 0.742014742014742, 0.7469287469287469, 0.7321867321867321, 0.7567567567567568, 0.7616707616707616, 0.7346437346437347, 0.7493857493857494, 0.7592137592137592, 0.7542997542997543, 0.7321867321867321, 0.7297297297297297, 0.7493857493857494, 0.7297297297297297, 0.7518427518427518, 0.7346437346437347, 0.7321867321867321, 0.7321867321867321, 0.7100737100737101, 0.7125307125307125, 0.742014742014742, 0.7125307125307125, 0.7125307125307125, 0.7321867321867321, 0.6855036855036855, 0.7469287469287469, 0.7444717444717445, 0.7272727272727273, 0.7125307125307125, 0.7174447174447175, 0.7100737100737101, 0.6928746928746928, 0.7125307125307125, 0.7027027027027027, 0.7223587223587223, 0.7051597051597052, 0.7346437346437347], 0.6: [0.4668304668304668, 0.4987714987714988, 0.48894348894348894, 0.5356265356265356, 0.5356265356265356, 0.4987714987714988, 0.5282555282555282, 0.5233415233415234, 0.5528255528255528, 0.5135135135135135, 0.5184275184275184, 0.5233415233415234, 0.5036855036855037, 0.4864864864864865, 0.5012285012285013, 0.5036855036855037, 0.4963144963144963, 0.5331695331695332, 0.5307125307125307, 0.515970515970516, 0.48894348894348894, 0.5208845208845209, 0.5135135135135135, 0.5233415233415234, 0.5036855036855037, 0.542997542997543, 0.5208845208845209, 0.5208845208845209, 0.542997542997543, 0.4963144963144963, 0.5307125307125307, 0.5307125307125307, 0.5184275184275184, 0.5528255528255528, 0.515970515970516, 0.5282555282555282, 0.5184275184275184, 0.5036855036855037, 0.5036855036855037, 0.5282555282555282, 0.5282555282555282, 0.5282555282555282, 0.5208845208845209, 0.5036855036855037, 0.5454545454545454, 0.5503685503685504, 0.5528255528255528, 0.5012285012285013, 0.5085995085995086, 0.5331695331695332, 0.542997542997543, 0.4864864864864865, 0.5257985257985258, 0.5307125307125307, 0.5405405405405406, 0.5601965601965602, 0.5257985257985258, 0.5331695331695332, 0.5135135135135135, 0.542997542997543, 0.44471744471744473, 0.4963144963144963, 0.5110565110565111, 0.48402948402948404, 0.4963144963144963, 0.5012285012285013, 0.5110565110565111, 0.5061425061425061, 0.5061425061425061, 0.48157248157248156, 0.4987714987714988, 0.4864864864864865, 0.4864864864864865, 0.5110565110565111, 0.5454545454545454, 0.5036855036855037, 0.47174447174447176, 0.48894348894348894, 0.4619164619164619, 0.48402948402948404], 0.8: [0.343980343980344, 0.32923832923832924, 0.3316953316953317, 0.343980343980344, 0.36855036855036855, 0.37346437346437344, 0.32678132678132676, 0.4103194103194103, 0.35626535626535627, 0.36363636363636365, 0.36855036855036855, 0.3538083538083538, 0.3808353808353808, 0.3906633906633907, 0.32678132678132676, 0.35626535626535627, 0.3906633906633907, 0.37346437346437344, 0.3759213759213759, 0.36363636363636365, 0.3538083538083538, 0.35872235872235875, 0.3366093366093366, 0.343980343980344, 0.3808353808353808, 0.3366093366093366, 0.3955773955773956, 0.36117936117936117, 0.3538083538083538, 0.3488943488943489, 0.37346437346437344, 0.343980343980344, 0.36363636363636365, 0.371007371007371, 0.33415233415233414, 0.32186732186732187, 0.3808353808353808, 0.36363636363636365, 0.32678132678132676, 0.3857493857493858, 0.40786240786240785, 0.36609336609336607, 0.3316953316953317, 0.33906633906633904, 0.3415233415233415, 0.35872235872235875, 0.35872235872235875, 0.40786240786240785, 0.343980343980344, 0.3538083538083538, 0.3783783783783784, 0.3488943488943489, 0.35872235872235875, 0.35872235872235875, 0.36117936117936117, 0.37346437346437344, 0.371007371007371, 0.3366093366093366, 0.40786240786240785, 0.39803439803439805, 0.343980343980344, 0.36117936117936117, 0.35872235872235875, 0.37346437346437344, 0.32678132678132676, 0.3366093366093366, 0.33906633906633904, 0.3144963144963145, 0.3464373464373464, 0.3194103194103194, 0.3366093366093366, 0.3144963144963145, 0.343980343980344, 0.3488943488943489, 0.3759213759213759, 0.31695331695331697, 0.3464373464373464, 0.3759213759213759, 0.28746928746928746, 0.3488943488943489], 1.0: [0.2727272727272727, 0.25307125307125306, 0.25061425061425063, 0.25307125307125306, 0.26044226044226043, 0.2751842751842752, 0.2751842751842752, 0.26044226044226043, 0.2678132678132678, 0.29975429975429974, 0.2751842751842752, 0.25061425061425063, 0.2457002457002457, 0.2628992628992629, 0.2727272727272727, 0.27764127764127766, 0.2678132678132678, 0.2678132678132678, 0.2678132678132678, 0.31203931203931207, 0.2628992628992629, 0.26044226044226043, 0.2457002457002457, 0.29484029484029484, 0.26535626535626533, 0.2285012285012285, 0.21867321867321868, 0.2702702702702703, 0.2628992628992629, 0.257985257985258, 0.24815724815724816, 0.25552825552825553, 0.23832923832923833, 0.24815724815724816, 0.24815724815724816, 0.2457002457002457, 0.22113022113022113, 0.20147420147420148, 0.257985257985258, 0.2972972972972973, 0.32186732186732187, 0.27764127764127766, 0.2702702702702703, 0.24815724815724816, 0.29975429975429974, 0.2334152334152334, 0.2628992628992629, 0.257985257985258, 0.2702702702702703, 0.26044226044226043, 0.2285012285012285, 0.29238329238329236, 0.2457002457002457, 0.27764127764127766, 0.2972972972972973, 0.2628992628992629, 0.26044226044226043, 0.2727272727272727, 0.2457002457002457, 0.25061425061425063, 0.2702702702702703, 0.2113022113022113, 0.2334152334152334, 0.28255528255528256, 0.25061425061425063, 0.2678132678132678, 0.21621621621621623, 0.25307125307125306, 0.27764127764127766, 0.2727272727272727, 0.2751842751842752, 0.23587223587223588, 0.25307125307125306, 0.23832923832923833, 0.2285012285012285, 0.24324324324324326, 0.23587223587223588, 0.23832923832923833, 0.21867321867321868, 0.257985257985258]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_reward = {0.3: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [92, 35, 156, 35, 147, 35, 167, 117, 35, 30, 35, 35, 63, 142, 30, 35, 83, 30, 67, 35, 63, 35, 35, 53, 30, 53, 30, 35, 35, 35, 30, 53, 117, 30, 35, 35, 35, 30, 35, 35, 63, 63, 53, 35, 72, 30, 35, 53, 30, 35, 30, 35, 131, 35, 5, 35, 57, 63, 172, 121, 35, 35, 116, 182, 35, 53, 136, 102, 35, 53, 35, 53, 35, 63, 5, 111, 63, 53, 35, 35], 0.4: [10, 25, 15, 0, 25, 0, 30, 0, 10, 25, 5, 25, 15, 25, 30, 10, 0, 5, 5, 5, 0, 10, 5, 10, 25, 0, 0, 0, 30, 0, 15, 0, 15, 0, 0, 10, 5, 10, 0, 35, 0, 10, 10, 30, 30, 10, 10, 10, 25, 15, 5, 0, 25, 0, 10, 0, 25, 25, 10, 25, 5, 0, 0, 5, 5, 0, 15, 0, 10, 15, 30, 10, 25, 15, 5, 10, 0, 5, 0, 15], 0.6: [0, 5, 0, 0, 35, 0, 10, 0, 10, 5, 0, 10, 0, 0, 0, 0, 5, 25, 5, 0, 0, 0, 0, 0, 10, 0, 5, 15, 0, 0, 0, 0, 0, 10, 0, 10, 0, 5, 25, 10, 0, 0, 0, 0, 0, 10, 10, 10, 0, 0, 0, 0, 0, 10, 0, 0, 10, 10, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0.8: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0], 1.0: [0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0]}, 0.5: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [53, 30, 35, 53, 53, 63, 30, 30, 35, 35, 35, 111, 35, 53, 53, 35, 35, 35, 35, 98, 121, 35, 30, 63, 30, 53, 35, 63, 35, 53, 67, 53, 30, 30, 30, 127, 112, 53, 35, 63, 35, 35, 72, 30, 63, 67, 53, 35, 111, 35, 63, 35, 53, 35, 63, 35, 35, 121, 35, 167, 35, 132, 147, 187, 223, 67, 67, 53, 63, 15, 35, 53, 240, 67, 53, 157, 233, 63, 15, 131], 0.4: [5, 5, 25, 25, 5, 15, 0, 25, 30, 10, 15, 15, 25, 0, 10, 10, 10, 0, 5, 15, 0, 0, 0, 0, 15, 25, 10, 15, 30, 25, 10, 25, 5, 25, 5, 5, 5, 0, 5, 15, 0, 5, 30, 10, 15, 25, 10, 5, 25, 10, 30, 0, 25, 30, 0, 0, 30, 10, 25, 15, 25, 5, 15, 25, 0, 0, 5, 0, 0, 30, 25, 10, 5, 10, 5, 15, 25, 15, 10, 15], 0.6: [10, 0, 0, 10, 0, 0, 0, 10, 0, 10, 0, 0, 10, 0, 25, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 10, 0, 5, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 10, 10, 25, 0, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 10, 10, 0, 0, 10, 0, 5, 0, 0, 0], 0.8: [0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10], 1.0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 0.7: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [63, 35, 30, 167, 202, 35, 35, 35, 35, 131, 35, 63, 35, 35, 35, 77, 127, 30, 35, 63, 92, 30, 35, 35, 35, 116, 25, 76, 30, 35, 30, 82, 63, 53, 35, 35, 97, 131, 178, 5, 30, 35, 35, 30, 53, 35, 25, 53, 53, 25, 5, 53, 30, 35, 25, 63, 25, 30, 35, 35, 53, 35, 35, 35, 96, 35, 35, 35, 53, 30, 30, 35, 35, 72, 35, 25, 151, 35, 96, 63], 0.4: [5, 0, 25, 5, 5, 30, 0, 10, 25, 0, 10, 5, 5, 0, 0, 10, 10, 35, 10, 25, 5, 0, 0, 0, 0, 5, 5, 0, 5, 15, 0, 25, 5, 10, 10, 0, 0, 5, 5, 30, 25, 10, 5, 5, 10, 10, 25, 0, 15, 15, 25, 15, 25, 25, 5, 30, 10, 0, 25, 15, 10, 10, 0, 35, 0, 25, 10, 10, 5, 5, 0, 25, 0, 0, 0, 0, 10, 10, 10, 10], 0.6: [5, 0, 0, 0, 0, 0, 10, 0, 10, 25, 0, 0, 15, 0, 10, 0, 0, 25, 0, 0, 10, 0, 5, 0, 10, 5, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 5, 0, 10, 0, 10, 0, 10, 0, 10, 25, 5, 10, 10, 10, 0, 0, 10, 10, 10, 0, 0, 10, 0, 0, 10], 0.8: [0, 0, 10, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 10, 0, 10, 10, 10, 0, 0, 0, 10, 0, 0, 10, 0, 0, 0, 0, 10, 10, 0, 0, 25, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 5, 0, 0, 0, 0, 10, 0, 0, 10], 1.0: [10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0]}, 0.9: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [53, 35, 25, 30, 30, 30, 30, 35, 101, 35, 63, 10, 35, 53, 30, 35, 53, 35, 30, 30, 35, 116, 111, 30, 35, 35, 35, 35, 101, 35, 30, 63, 53, 35, 35, 25, 35, 35, 35, 30, 67, 35, 152, 35, 53, 53, 5, 30, 5, 35, 35, 30, 35, 35, 97, 35, 25, 30, 30, 30, 30, 35, 30, 61, 67, 30, 63, 30, 15, 15, 53, 5, 30, 15, 59, 30, 30, 84, 15, 30], 0.4: [0, 15, 15, 15, 0, 10, 5, 30, 30, 0, 10, 0, 10, 35, 5, 25, 5, 25, 25, 10, 10, 30, 0, 20, 0, 30, 5, 25, 5, 5, 25, 25, 0, 10, 25, 5, 10, 5, 5, 0, 5, 10, 25, 10, 0, 25, 10, 30, 30, 0, 30, 25, 10, 15, 10, 10, 25, 10, 15, 0, 0, 15, 25, 0, 0, 10, 5, 25, 5, 25, 5, 30, 25, 35, 10, 30, 10, 25, 0, 0], 0.6: [10, 0, 10, 0, 10, 0, 0, 10, 0, 0, 0, 25, 0, 0, 0, 0, 0, 10, 0, 10, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 10, 0, 0, 10, 0, 0, 10, 25, 0, 10, 0, 0, 10, 0, 0, 5, 0, 0, 0, 10, 0, 10, 0, 0, 5, 10, 0, 0, 0, 10, 0, 10, 0, 0, 10, 0, 0, 10, 10, 0, 0, 10, 0], 0.8: [0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 25, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 10, 5, 0, 10, 0, 10, 10, 0, 0, 0, 0], 1.0: [10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 25, 0, 10, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 10, 10, 10, 10, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 5, 0, 0, 10, 0, 0]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_accuracy = {}\n",
    "\n",
    "for threshold in [0.3, 0.5, 0.7, 0.9]:\n",
    "    results_accuracy[threshold] = {}\n",
    "    for snr in [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        results_accuracy[threshold][snr] = []\n",
    "        for subdir in range(4):\n",
    "            full_path = path + str(subdir) + '/20000'\n",
    "            network.load_state_dict(torch.load(full_path + '/network'))\n",
    "            for result in test_accuracy(False, threshold, snr, 20):\n",
    "                results_accuracy[threshold][snr].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.3: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.9754299754299754, 0.9656019656019657, 0.9508599508599509, 0.9656019656019657, 0.9606879606879607, 0.972972972972973, 0.9680589680589681, 0.9705159705159705, 0.9631449631449631, 0.9803439803439803, 0.9582309582309583, 0.9631449631449631, 0.9631449631449631, 0.9680589680589681, 0.9705159705159705, 0.9656019656019657, 0.9582309582309583, 0.9705159705159705, 0.9656019656019657, 0.972972972972973, 0.9705159705159705, 0.9705159705159705, 0.972972972972973, 0.9606879606879607, 0.9606879606879607, 0.9754299754299754, 0.972972972972973, 0.9656019656019657, 0.9631449631449631, 0.9631449631449631, 0.9631449631449631, 0.972972972972973, 0.9705159705159705, 0.9606879606879607, 0.9778869778869779, 0.9631449631449631, 0.9557739557739557, 0.9631449631449631, 0.9656019656019657, 0.9656019656019657, 0.9533169533169533, 0.9557739557739557, 0.972972972972973, 0.9852579852579852, 0.9680589680589681, 0.9803439803439803, 0.9754299754299754, 0.9680589680589681, 0.9656019656019657, 0.9803439803439803, 0.972972972972973, 0.9705159705159705, 0.9606879606879607, 0.9631449631449631, 0.972972972972973, 0.9828009828009828, 0.9778869778869779, 0.9656019656019657, 0.9705159705159705, 0.9754299754299754, 0.9606879606879607, 0.9631449631449631, 0.9778869778869779, 0.9754299754299754, 0.9705159705159705, 0.9606879606879607, 0.9680589680589681, 0.9582309582309583, 0.9656019656019657, 0.9631449631449631, 0.9582309582309583, 0.9631449631449631, 0.9631449631449631, 0.9680589680589681, 0.9582309582309583, 0.9705159705159705, 0.9606879606879607, 0.9606879606879607, 0.9754299754299754, 0.9852579852579852], 0.4: [0.8132678132678133, 0.7518427518427518, 0.7395577395577395, 0.7936117936117936, 0.7272727272727273, 0.7321867321867321, 0.7665847665847666, 0.7346437346437347, 0.7518427518427518, 0.7223587223587223, 0.769041769041769, 0.7641277641277642, 0.7714987714987716, 0.7395577395577395, 0.7592137592137592, 0.7936117936117936, 0.7813267813267813, 0.7714987714987716, 0.7788697788697788, 0.7641277641277642, 0.773955773955774, 0.7518427518427518, 0.7469287469287469, 0.7641277641277642, 0.7764127764127764, 0.7911547911547911, 0.773955773955774, 0.7371007371007371, 0.7518427518427518, 0.7567567567567568, 0.7542997542997543, 0.7764127764127764, 0.773955773955774, 0.7444717444717445, 0.7272727272727273, 0.769041769041769, 0.7371007371007371, 0.7911547911547911, 0.7542997542997543, 0.7641277641277642, 0.7985257985257985, 0.8058968058968059, 0.7542997542997543, 0.7542997542997543, 0.8034398034398035, 0.773955773955774, 0.7788697788697788, 0.773955773955774, 0.8108108108108109, 0.7518427518427518, 0.7788697788697788, 0.8329238329238329, 0.7542997542997543, 0.7862407862407862, 0.7641277641277642, 0.7837837837837838, 0.7518427518427518, 0.7960687960687961, 0.7567567567567568, 0.8083538083538083, 0.7714987714987716, 0.7837837837837838, 0.7567567567567568, 0.714987714987715, 0.7641277641277642, 0.7199017199017199, 0.7714987714987716, 0.7395577395577395, 0.7567567567567568, 0.7321867321867321, 0.7518427518427518, 0.7297297297297297, 0.7764127764127764, 0.7542997542997543, 0.7444717444717445, 0.773955773955774, 0.7297297297297297, 0.7321867321867321, 0.7444717444717445, 0.7788697788697788], 0.6: [0.5233415233415234, 0.5036855036855037, 0.515970515970516, 0.542997542997543, 0.5282555282555282, 0.5085995085995086, 0.5135135135135135, 0.5208845208845209, 0.5307125307125307, 0.47665847665847666, 0.5135135135135135, 0.5208845208845209, 0.5405405405405406, 0.5626535626535627, 0.5282555282555282, 0.538083538083538, 0.515970515970516, 0.5036855036855037, 0.5307125307125307, 0.5233415233415234, 0.49385749385749383, 0.47174447174447176, 0.5331695331695332, 0.5331695331695332, 0.5257985257985258, 0.5110565110565111, 0.515970515970516, 0.5110565110565111, 0.542997542997543, 0.5331695331695332, 0.5282555282555282, 0.547911547911548, 0.457002457002457, 0.515970515970516, 0.48894348894348894, 0.4914004914004914, 0.5282555282555282, 0.4963144963144963, 0.4594594594594595, 0.547911547911548, 0.48894348894348894, 0.5208845208845209, 0.5307125307125307, 0.5700245700245701, 0.515970515970516, 0.547911547911548, 0.542997542997543, 0.5307125307125307, 0.5356265356265356, 0.515970515970516, 0.5503685503685504, 0.5601965601965602, 0.5184275184275184, 0.5307125307125307, 0.4914004914004914, 0.5724815724815725, 0.4742014742014742, 0.5773955773955773, 0.5282555282555282, 0.5331695331695332, 0.47911547911547914, 0.515970515970516, 0.4619164619164619, 0.4692874692874693, 0.5135135135135135, 0.4692874692874693, 0.5135135135135135, 0.542997542997543, 0.48402948402948404, 0.48894348894348894, 0.4668304668304668, 0.44717444717444715, 0.5012285012285013, 0.48157248157248156, 0.538083538083538, 0.5012285012285013, 0.48402948402948404, 0.515970515970516, 0.5085995085995086, 0.4643734643734644], 0.8: [0.35626535626535627, 0.3832923832923833, 0.371007371007371, 0.36855036855036855, 0.39803439803439805, 0.3759213759213759, 0.3955773955773956, 0.3832923832923833, 0.3046683046683047, 0.3366093366093366, 0.3832923832923833, 0.36609336609336607, 0.3046683046683047, 0.35626535626535627, 0.371007371007371, 0.31695331695331697, 0.3538083538083538, 0.36363636363636365, 0.32186732186732187, 0.3366093366093366, 0.3464373464373464, 0.3366093366093366, 0.3415233415233415, 0.35135135135135137, 0.35872235872235875, 0.3955773955773956, 0.3857493857493858, 0.32923832923832924, 0.36609336609336607, 0.3316953316953317, 0.343980343980344, 0.35872235872235875, 0.35135135135135137, 0.32678132678132676, 0.36855036855036855, 0.3464373464373464, 0.33906633906633904, 0.3316953316953317, 0.37346437346437344, 0.3488943488943489, 0.36363636363636365, 0.35872235872235875, 0.36609336609336607, 0.3538083538083538, 0.36363636363636365, 0.35626535626535627, 0.343980343980344, 0.3415233415233415, 0.35872235872235875, 0.371007371007371, 0.35626535626535627, 0.3366093366093366, 0.3783783783783784, 0.35626535626535627, 0.33415233415233414, 0.343980343980344, 0.3783783783783784, 0.36609336609336607, 0.3538083538083538, 0.35626535626535627, 0.29975429975429974, 0.3488943488943489, 0.33906633906633904, 0.32923832923832924, 0.3464373464373464, 0.36855036855036855, 0.3808353808353808, 0.3316953316953317, 0.3095823095823096, 0.33415233415233414, 0.3415233415233415, 0.3488943488943489, 0.28746928746928746, 0.3194103194103194, 0.3046683046683047, 0.32923832923832924, 0.35135135135135137, 0.28746928746928746, 0.31695331695331697, 0.25552825552825553], 1.0: [0.23587223587223588, 0.2285012285012285, 0.2628992628992629, 0.2678132678132678, 0.2628992628992629, 0.23587223587223588, 0.2727272727272727, 0.25061425061425063, 0.23587223587223588, 0.24324324324324326, 0.22358722358722358, 0.25061425061425063, 0.2678132678132678, 0.24324324324324326, 0.24815724815724816, 0.23587223587223588, 0.2628992628992629, 0.2800982800982801, 0.2457002457002457, 0.2727272727272727, 0.2457002457002457, 0.26535626535626533, 0.24324324324324326, 0.2727272727272727, 0.26044226044226043, 0.23095823095823095, 0.2800982800982801, 0.23095823095823095, 0.23587223587223588, 0.25061425061425063, 0.22604422604422605, 0.24815724815724816, 0.24324324324324326, 0.24324324324324326, 0.24324324324324326, 0.2457002457002457, 0.2334152334152334, 0.22113022113022113, 0.22358722358722358, 0.22358722358722358, 0.28501228501228504, 0.23587223587223588, 0.25552825552825553, 0.257985257985258, 0.2334152334152334, 0.25307125307125306, 0.26044226044226043, 0.24078624078624078, 0.28746928746928746, 0.28255528255528256, 0.2628992628992629, 0.26044226044226043, 0.2727272727272727, 0.25307125307125306, 0.25307125307125306, 0.25307125307125306, 0.21621621621621623, 0.2727272727272727, 0.26044226044226043, 0.24078624078624078, 0.22358722358722358, 0.22604422604422605, 0.2457002457002457, 0.2457002457002457, 0.23587223587223588, 0.25061425061425063, 0.23587223587223588, 0.25552825552825553, 0.20638820638820637, 0.21375921375921375, 0.21867321867321868, 0.21867321867321868, 0.21375921375921375, 0.22604422604422605, 0.21867321867321868, 0.21867321867321868, 0.22604422604422605, 0.22358722358722358, 0.19656019656019655, 0.20393120393120392]}, 0.5: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.9631449631449631, 0.9606879606879607, 0.9754299754299754, 0.9606879606879607, 0.9680589680589681, 0.9705159705159705, 0.9877149877149877, 0.9680589680589681, 0.9803439803439803, 0.9680589680589681, 0.9803439803439803, 0.9680589680589681, 0.9754299754299754, 0.9705159705159705, 0.9852579852579852, 0.9852579852579852, 0.9926289926289926, 0.972972972972973, 0.9680589680589681, 0.9606879606879607, 0.9803439803439803, 0.9680589680589681, 0.9656019656019657, 0.972972972972973, 0.972972972972973, 0.9778869778869779, 0.9705159705159705, 0.9656019656019657, 0.9705159705159705, 0.9582309582309583, 0.9705159705159705, 0.9754299754299754, 0.9803439803439803, 0.9557739557739557, 0.972972972972973, 0.972972972972973, 0.9754299754299754, 0.9631449631449631, 0.9754299754299754, 0.9680589680589681, 0.9778869778869779, 0.9631449631449631, 0.9656019656019657, 0.9582309582309583, 0.9656019656019657, 0.9754299754299754, 0.9680589680589681, 0.9778869778869779, 0.972972972972973, 0.9778869778869779, 0.9778869778869779, 0.9606879606879607, 0.9606879606879607, 0.9754299754299754, 0.9705159705159705, 0.9705159705159705, 0.9803439803439803, 0.9705159705159705, 0.9705159705159705, 0.9778869778869779, 0.972972972972973, 0.9852579852579852, 0.972972972972973, 0.9582309582309583, 0.9778869778869779, 0.9582309582309583, 0.9606879606879607, 0.9705159705159705, 0.9680589680589681, 0.9754299754299754, 0.972972972972973, 0.9656019656019657, 0.9631449631449631, 0.9754299754299754, 0.9582309582309583, 0.9606879606879607, 0.9631449631449631, 0.9582309582309583, 0.9656019656019657, 0.9606879606879607], 0.4: [0.773955773955774, 0.7395577395577395, 0.7714987714987716, 0.7641277641277642, 0.7641277641277642, 0.7469287469287469, 0.7764127764127764, 0.769041769041769, 0.7518427518427518, 0.7764127764127764, 0.7641277641277642, 0.8034398034398035, 0.7272727272727273, 0.742014742014742, 0.7788697788697788, 0.742014742014742, 0.742014742014742, 0.7567567567567568, 0.7469287469287469, 0.7641277641277642, 0.769041769041769, 0.7493857493857494, 0.7542997542997543, 0.769041769041769, 0.7714987714987716, 0.7567567567567568, 0.7469287469287469, 0.7837837837837838, 0.7444717444717445, 0.7813267813267813, 0.7862407862407862, 0.7592137592137592, 0.7592137592137592, 0.7911547911547911, 0.7665847665847666, 0.7567567567567568, 0.7764127764127764, 0.7862407862407862, 0.7886977886977887, 0.7371007371007371, 0.773955773955774, 0.773955773955774, 0.7813267813267813, 0.7493857493857494, 0.769041769041769, 0.773955773955774, 0.7788697788697788, 0.7469287469287469, 0.7714987714987716, 0.8108108108108109, 0.7837837837837838, 0.7493857493857494, 0.7616707616707616, 0.7714987714987716, 0.7371007371007371, 0.7837837837837838, 0.7493857493857494, 0.8108108108108109, 0.769041769041769, 0.7837837837837838, 0.7493857493857494, 0.7444717444717445, 0.7321867321867321, 0.7592137592137592, 0.742014742014742, 0.7567567567567568, 0.769041769041769, 0.7616707616707616, 0.7518427518427518, 0.7297297297297297, 0.7174447174447175, 0.7542997542997543, 0.7346437346437347, 0.7469287469287469, 0.7100737100737101, 0.7518427518427518, 0.7469287469287469, 0.7100737100737101, 0.7248157248157249, 0.7223587223587223], 0.6: [0.5454545454545454, 0.5282555282555282, 0.5085995085995086, 0.5626535626535627, 0.5331695331695332, 0.5528255528255528, 0.5061425061425061, 0.5036855036855037, 0.538083538083538, 0.5307125307125307, 0.5184275184275184, 0.538083538083538, 0.5061425061425061, 0.5012285012285013, 0.5307125307125307, 0.5085995085995086, 0.4963144963144963, 0.515970515970516, 0.5552825552825553, 0.48402948402948404, 0.5135135135135135, 0.5528255528255528, 0.5233415233415234, 0.538083538083538, 0.5012285012285013, 0.5257985257985258, 0.5503685503685504, 0.5085995085995086, 0.5454545454545454, 0.5012285012285013, 0.547911547911548, 0.5233415233415234, 0.5528255528255528, 0.4987714987714988, 0.5405405405405406, 0.5528255528255528, 0.47665847665847666, 0.5823095823095823, 0.48894348894348894, 0.5184275184275184, 0.5184275184275184, 0.5405405405405406, 0.5577395577395577, 0.5626535626535627, 0.47665847665847666, 0.5773955773955773, 0.5454545454545454, 0.5184275184275184, 0.5405405405405406, 0.515970515970516, 0.5503685503685504, 0.5061425061425061, 0.5454545454545454, 0.47911547911547914, 0.5282555282555282, 0.5282555282555282, 0.5331695331695332, 0.5184275184275184, 0.5085995085995086, 0.5012285012285013, 0.5085995085995086, 0.5208845208845209, 0.47174447174447176, 0.4987714987714988, 0.4643734643734644, 0.4963144963144963, 0.5085995085995086, 0.4914004914004914, 0.4643734643734644, 0.4864864864864865, 0.5208845208845209, 0.538083538083538, 0.5233415233415234, 0.48157248157248156, 0.515970515970516, 0.5110565110565111, 0.49385749385749383, 0.5110565110565111, 0.5061425061425061, 0.515970515970516], 0.8: [0.343980343980344, 0.3808353808353808, 0.32923832923832924, 0.32678132678132676, 0.3366093366093366, 0.3783783783783784, 0.35135135135135137, 0.3857493857493858, 0.3464373464373464, 0.36117936117936117, 0.3759213759213759, 0.35626535626535627, 0.3464373464373464, 0.37346437346437344, 0.3538083538083538, 0.3488943488943489, 0.3194103194103194, 0.35626535626535627, 0.36855036855036855, 0.41277641277641275, 0.3488943488943489, 0.3488943488943489, 0.3464373464373464, 0.3366093366093366, 0.36609336609336607, 0.35872235872235875, 0.36363636363636365, 0.35135135135135137, 0.4004914004914005, 0.3316953316953317, 0.4004914004914005, 0.3857493857493858, 0.35135135135135137, 0.35626535626535627, 0.36117936117936117, 0.3194103194103194, 0.32186732186732187, 0.371007371007371, 0.3095823095823096, 0.4103194103194103, 0.3415233415233415, 0.3488943488943489, 0.3464373464373464, 0.36117936117936117, 0.3464373464373464, 0.36609336609336607, 0.3808353808353808, 0.31695331695331697, 0.37346437346437344, 0.36855036855036855, 0.343980343980344, 0.371007371007371, 0.3783783783783784, 0.3488943488943489, 0.32923832923832924, 0.3464373464373464, 0.3832923832923833, 0.3415233415233415, 0.3464373464373464, 0.36609336609336607, 0.3071253071253071, 0.3366093366093366, 0.3316953316953317, 0.33906633906633904, 0.343980343980344, 0.32923832923832924, 0.36117936117936117, 0.27764127764127766, 0.3316953316953317, 0.32678132678132676, 0.32432432432432434, 0.3415233415233415, 0.32432432432432434, 0.3071253071253071, 0.33415233415233414, 0.3144963144963145, 0.371007371007371, 0.3194103194103194, 0.343980343980344, 0.3488943488943489], 1.0: [0.2113022113022113, 0.23587223587223588, 0.2727272727272727, 0.257985257985258, 0.21375921375921375, 0.28255528255528256, 0.2334152334152334, 0.257985257985258, 0.257985257985258, 0.24078624078624078, 0.23587223587223588, 0.25061425061425063, 0.26535626535626533, 0.2334152334152334, 0.25552825552825553, 0.2678132678132678, 0.28255528255528256, 0.26044226044226043, 0.22113022113022113, 0.28746928746928746, 0.2678132678132678, 0.24815724815724816, 0.2628992628992629, 0.2628992628992629, 0.2702702702702703, 0.23095823095823095, 0.2334152334152334, 0.257985257985258, 0.26044226044226043, 0.20884520884520885, 0.22113022113022113, 0.2334152334152334, 0.24324324324324326, 0.25061425061425063, 0.23587223587223588, 0.25307125307125306, 0.21621621621621623, 0.2702702702702703, 0.23587223587223588, 0.23587223587223588, 0.23832923832923833, 0.25307125307125306, 0.25552825552825553, 0.26044226044226043, 0.24815724815724816, 0.24815724815724816, 0.20147420147420148, 0.21867321867321868, 0.25061425061425063, 0.257985257985258, 0.25307125307125306, 0.2678132678132678, 0.257985257985258, 0.2800982800982801, 0.22113022113022113, 0.25061425061425063, 0.2727272727272727, 0.257985257985258, 0.25061425061425063, 0.24324324324324326, 0.22358722358722358, 0.24078624078624078, 0.21867321867321868, 0.24324324324324326, 0.26535626535626533, 0.25552825552825553, 0.20884520884520885, 0.25061425061425063, 0.23832923832923833, 0.22358722358722358, 0.26044226044226043, 0.2678132678132678, 0.24815724815724816, 0.23832923832923833, 0.19656019656019655, 0.2457002457002457, 0.24324324324324326, 0.25552825552825553, 0.22358722358722358, 0.2457002457002457]}, 0.7: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.9680589680589681, 0.9557739557739557, 0.9631449631449631, 0.9705159705159705, 0.9631449631449631, 0.9606879606879607, 0.9680589680589681, 0.9778869778869779, 0.9680589680589681, 0.9533169533169533, 0.9705159705159705, 0.9606879606879607, 0.9631449631449631, 0.9631449631449631, 0.9631449631449631, 0.9852579852579852, 0.972972972972973, 0.9680589680589681, 0.972972972972973, 0.9778869778869779, 0.9705159705159705, 0.9680589680589681, 0.9656019656019657, 0.9582309582309583, 0.9557739557739557, 0.972972972972973, 0.9656019656019657, 0.9606879606879607, 0.972972972972973, 0.9754299754299754, 0.9533169533169533, 0.9582309582309583, 0.972972972972973, 0.972972972972973, 0.9631449631449631, 0.9680589680589681, 0.9803439803439803, 0.9582309582309583, 0.9778869778869779, 0.9705159705159705, 0.9680589680589681, 0.9582309582309583, 0.9582309582309583, 0.9778869778869779, 0.9705159705159705, 0.9680589680589681, 0.9582309582309583, 0.9705159705159705, 0.972972972972973, 0.972972972972973, 0.9778869778869779, 0.9803439803439803, 0.9705159705159705, 0.972972972972973, 0.9828009828009828, 0.9705159705159705, 0.9705159705159705, 0.9557739557739557, 0.972972972972973, 0.9582309582309583, 0.9803439803439803, 0.9631449631449631, 0.9631449631449631, 0.9533169533169533, 0.9606879606879607, 0.9582309582309583, 0.9557739557739557, 0.9508599508599509, 0.9606879606879607, 0.9631449631449631, 0.9557739557739557, 0.9656019656019657, 0.9434889434889435, 0.9631449631449631, 0.9606879606879607, 0.9656019656019657, 0.9778869778869779, 0.972972972972973, 0.972972972972973, 0.9606879606879607], 0.4: [0.7518427518427518, 0.7592137592137592, 0.7469287469287469, 0.769041769041769, 0.7764127764127764, 0.7592137592137592, 0.7248157248157249, 0.7641277641277642, 0.7936117936117936, 0.7518427518427518, 0.7764127764127764, 0.7346437346437347, 0.7567567567567568, 0.773955773955774, 0.7542997542997543, 0.7395577395577395, 0.769041769041769, 0.773955773955774, 0.7788697788697788, 0.7960687960687961, 0.7567567567567568, 0.773955773955774, 0.7444717444717445, 0.7567567567567568, 0.7469287469287469, 0.769041769041769, 0.7714987714987716, 0.7469287469287469, 0.7542997542997543, 0.7837837837837838, 0.7321867321867321, 0.7788697788697788, 0.7714987714987716, 0.7862407862407862, 0.7592137592137592, 0.7641277641277642, 0.7542997542997543, 0.7665847665847666, 0.7444717444717445, 0.7764127764127764, 0.7567567567567568, 0.7444717444717445, 0.7665847665847666, 0.7764127764127764, 0.7665847665847666, 0.8034398034398035, 0.7518427518427518, 0.8034398034398035, 0.7764127764127764, 0.769041769041769, 0.7886977886977887, 0.7764127764127764, 0.7936117936117936, 0.7936117936117936, 0.7714987714987716, 0.7542997542997543, 0.7862407862407862, 0.7641277641277642, 0.769041769041769, 0.7788697788697788, 0.7223587223587223, 0.7174447174447175, 0.7518427518427518, 0.7518427518427518, 0.7321867321867321, 0.7592137592137592, 0.7321867321867321, 0.7444717444717445, 0.7346437346437347, 0.7297297297297297, 0.7641277641277642, 0.7272727272727273, 0.7100737100737101, 0.7616707616707616, 0.7395577395577395, 0.7321867321867321, 0.7469287469287469, 0.7297297297297297, 0.7444717444717445, 0.7444717444717445], 0.6: [0.5110565110565111, 0.5307125307125307, 0.5528255528255528, 0.5626535626535627, 0.515970515970516, 0.5503685503685504, 0.5577395577395577, 0.5233415233415234, 0.5257985257985258, 0.5233415233415234, 0.515970515970516, 0.4864864864864865, 0.5110565110565111, 0.5749385749385749, 0.538083538083538, 0.5233415233415234, 0.5135135135135135, 0.5282555282555282, 0.4963144963144963, 0.547911547911548, 0.5577395577395577, 0.5208845208845209, 0.5405405405405406, 0.5208845208845209, 0.538083538083538, 0.542997542997543, 0.5331695331695332, 0.5233415233415234, 0.5503685503685504, 0.5405405405405406, 0.5233415233415234, 0.515970515970516, 0.5282555282555282, 0.5233415233415234, 0.5282555282555282, 0.6044226044226044, 0.5233415233415234, 0.5233415233415234, 0.5135135135135135, 0.5307125307125307, 0.5773955773955773, 0.5405405405405406, 0.5749385749385749, 0.5061425061425061, 0.5823095823095823, 0.49385749385749383, 0.542997542997543, 0.5331695331695332, 0.5552825552825553, 0.5405405405405406, 0.5307125307125307, 0.5307125307125307, 0.5503685503685504, 0.5724815724815725, 0.5528255528255528, 0.5307125307125307, 0.5626535626535627, 0.5552825552825553, 0.5307125307125307, 0.5331695331695332, 0.4987714987714988, 0.4643734643734644, 0.5135135135135135, 0.5036855036855037, 0.5208845208845209, 0.4987714987714988, 0.5012285012285013, 0.49385749385749383, 0.5282555282555282, 0.4668304668304668, 0.4742014742014742, 0.5135135135135135, 0.4668304668304668, 0.5208845208845209, 0.5061425061425061, 0.4864864864864865, 0.47665847665847666, 0.5233415233415234, 0.47911547911547914, 0.47911547911547914], 0.8: [0.3783783783783784, 0.36609336609336607, 0.35626535626535627, 0.3906633906633907, 0.3955773955773956, 0.3857493857493858, 0.3464373464373464, 0.33415233415233414, 0.371007371007371, 0.3488943488943489, 0.3488943488943489, 0.35135135135135137, 0.35135135135135137, 0.31695331695331697, 0.3906633906633907, 0.36855036855036855, 0.35872235872235875, 0.35872235872235875, 0.4004914004914005, 0.36609336609336607, 0.40786240786240785, 0.35872235872235875, 0.35135135135135137, 0.3906633906633907, 0.33906633906633904, 0.32923832923832924, 0.36363636363636365, 0.36363636363636365, 0.36363636363636365, 0.3783783783783784, 0.35135135135135137, 0.3906633906633907, 0.3857493857493858, 0.31695331695331697, 0.36609336609336607, 0.3808353808353808, 0.35135135135135137, 0.3488943488943489, 0.3783783783783784, 0.32186732186732187, 0.35872235872235875, 0.39803439803439805, 0.3538083538083538, 0.3759213759213759, 0.3783783783783784, 0.3783783783783784, 0.3906633906633907, 0.3783783783783784, 0.3955773955773956, 0.3955773955773956, 0.36117936117936117, 0.36363636363636365, 0.32923832923832924, 0.36609336609336607, 0.32923832923832924, 0.33415233415233414, 0.39803439803439805, 0.37346437346437344, 0.33415233415233414, 0.3464373464373464, 0.3316953316953317, 0.35872235872235875, 0.32186732186732187, 0.3832923832923833, 0.3538083538083538, 0.33906633906633904, 0.3488943488943489, 0.3759213759213759, 0.31203931203931207, 0.28992628992628994, 0.3194103194103194, 0.33415233415233414, 0.32678132678132676, 0.31695331695331697, 0.3095823095823096, 0.3366093366093366, 0.36117936117936117, 0.37346437346437344, 0.3415233415233415, 0.32923832923832924], 1.0: [0.2628992628992629, 0.2628992628992629, 0.2628992628992629, 0.2702702702702703, 0.26044226044226043, 0.2457002457002457, 0.257985257985258, 0.28992628992628994, 0.24078624078624078, 0.2334152334152334, 0.24324324324324326, 0.24815724815724816, 0.22604422604422605, 0.28992628992628994, 0.25307125307125306, 0.257985257985258, 0.257985257985258, 0.3071253071253071, 0.2702702702702703, 0.2285012285012285, 0.24815724815724816, 0.26044226044226043, 0.2727272727272727, 0.20393120393120392, 0.2628992628992629, 0.28746928746928746, 0.26535626535626533, 0.2727272727272727, 0.28501228501228504, 0.25061425061425063, 0.26535626535626533, 0.257985257985258, 0.2702702702702703, 0.257985257985258, 0.27764127764127766, 0.31695331695331697, 0.25307125307125306, 0.2334152334152334, 0.23832923832923833, 0.22604422604422605, 0.29975429975429974, 0.2727272727272727, 0.25307125307125306, 0.28746928746928746, 0.26535626535626533, 0.24324324324324326, 0.27764127764127766, 0.2751842751842752, 0.26044226044226043, 0.2751842751842752, 0.28992628992628994, 0.2800982800982801, 0.25307125307125306, 0.2727272727272727, 0.23095823095823095, 0.24078624078624078, 0.25552825552825553, 0.2800982800982801, 0.2727272727272727, 0.2800982800982801, 0.22604422604422605, 0.21867321867321868, 0.26044226044226043, 0.22604422604422605, 0.25552825552825553, 0.21867321867321868, 0.23095823095823095, 0.23095823095823095, 0.2113022113022113, 0.24078624078624078, 0.2334152334152334, 0.25061425061425063, 0.2457002457002457, 0.2702702702702703, 0.23832923832923833, 0.26044226044226043, 0.257985257985258, 0.23095823095823095, 0.24078624078624078, 0.2727272727272727]}, 0.9: {0.0: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.2: [0.941031941031941, 0.9557739557739557, 0.9336609336609336, 0.9533169533169533, 0.9606879606879607, 0.9582309582309583, 0.9533169533169533, 0.9459459459459459, 0.9606879606879607, 0.9582309582309583, 0.9680589680589681, 0.9533169533169533, 0.9705159705159705, 0.9508599508599509, 0.9484029484029484, 0.9656019656019657, 0.9533169533169533, 0.9533169533169533, 0.9484029484029484, 0.9705159705159705, 0.9582309582309583, 0.9533169533169533, 0.9582309582309583, 0.9582309582309583, 0.9459459459459459, 0.9508599508599509, 0.941031941031941, 0.9557739557739557, 0.9631449631449631, 0.9557739557739557, 0.9606879606879607, 0.9778869778869779, 0.9533169533169533, 0.9508599508599509, 0.9557739557739557, 0.941031941031941, 0.9557739557739557, 0.9533169533169533, 0.9434889434889435, 0.9656019656019657, 0.9705159705159705, 0.9434889434889435, 0.9582309582309583, 0.9582309582309583, 0.9459459459459459, 0.9582309582309583, 0.9631449631449631, 0.9754299754299754, 0.9606879606879607, 0.9533169533169533, 0.9606879606879607, 0.9631449631449631, 0.9606879606879607, 0.9557739557739557, 0.9754299754299754, 0.9557739557739557, 0.9606879606879607, 0.9656019656019657, 0.9656019656019657, 0.941031941031941, 0.9459459459459459, 0.9484029484029484, 0.9459459459459459, 0.9312039312039312, 0.9508599508599509, 0.9459459459459459, 0.9606879606879607, 0.9336609336609336, 0.9508599508599509, 0.9459459459459459, 0.9582309582309583, 0.9582309582309583, 0.9459459459459459, 0.9533169533169533, 0.9508599508599509, 0.9754299754299754, 0.9434889434889435, 0.9533169533169533, 0.9557739557739557, 0.9508599508599509], 0.4: [0.7444717444717445, 0.7076167076167076, 0.773955773955774, 0.7321867321867321, 0.7567567567567568, 0.7616707616707616, 0.7592137592137592, 0.7567567567567568, 0.7567567567567568, 0.7616707616707616, 0.7223587223587223, 0.7199017199017199, 0.7125307125307125, 0.7297297297297297, 0.7346437346437347, 0.7395577395577395, 0.7297297297297297, 0.7174447174447175, 0.7321867321867321, 0.7174447174447175, 0.7395577395577395, 0.7051597051597052, 0.7469287469287469, 0.6928746928746928, 0.7248157248157249, 0.7395577395577395, 0.6928746928746928, 0.7051597051597052, 0.7174447174447175, 0.7567567567567568, 0.742014742014742, 0.7371007371007371, 0.7174447174447175, 0.7321867321867321, 0.7100737100737101, 0.742014742014742, 0.742014742014742, 0.7125307125307125, 0.7297297297297297, 0.7248157248157249, 0.7223587223587223, 0.7395577395577395, 0.7395577395577395, 0.7567567567567568, 0.742014742014742, 0.7469287469287469, 0.7321867321867321, 0.7567567567567568, 0.7616707616707616, 0.7346437346437347, 0.7493857493857494, 0.7592137592137592, 0.7542997542997543, 0.7321867321867321, 0.7297297297297297, 0.7493857493857494, 0.7297297297297297, 0.7518427518427518, 0.7346437346437347, 0.7321867321867321, 0.7321867321867321, 0.7100737100737101, 0.7125307125307125, 0.742014742014742, 0.7125307125307125, 0.7125307125307125, 0.7321867321867321, 0.6855036855036855, 0.7469287469287469, 0.7444717444717445, 0.7272727272727273, 0.7125307125307125, 0.7174447174447175, 0.7100737100737101, 0.6928746928746928, 0.7125307125307125, 0.7027027027027027, 0.7223587223587223, 0.7051597051597052, 0.7346437346437347], 0.6: [0.4668304668304668, 0.4987714987714988, 0.48894348894348894, 0.5356265356265356, 0.5356265356265356, 0.4987714987714988, 0.5282555282555282, 0.5233415233415234, 0.5528255528255528, 0.5135135135135135, 0.5184275184275184, 0.5233415233415234, 0.5036855036855037, 0.4864864864864865, 0.5012285012285013, 0.5036855036855037, 0.4963144963144963, 0.5331695331695332, 0.5307125307125307, 0.515970515970516, 0.48894348894348894, 0.5208845208845209, 0.5135135135135135, 0.5233415233415234, 0.5036855036855037, 0.542997542997543, 0.5208845208845209, 0.5208845208845209, 0.542997542997543, 0.4963144963144963, 0.5307125307125307, 0.5307125307125307, 0.5184275184275184, 0.5528255528255528, 0.515970515970516, 0.5282555282555282, 0.5184275184275184, 0.5036855036855037, 0.5036855036855037, 0.5282555282555282, 0.5282555282555282, 0.5282555282555282, 0.5208845208845209, 0.5036855036855037, 0.5454545454545454, 0.5503685503685504, 0.5528255528255528, 0.5012285012285013, 0.5085995085995086, 0.5331695331695332, 0.542997542997543, 0.4864864864864865, 0.5257985257985258, 0.5307125307125307, 0.5405405405405406, 0.5601965601965602, 0.5257985257985258, 0.5331695331695332, 0.5135135135135135, 0.542997542997543, 0.44471744471744473, 0.4963144963144963, 0.5110565110565111, 0.48402948402948404, 0.4963144963144963, 0.5012285012285013, 0.5110565110565111, 0.5061425061425061, 0.5061425061425061, 0.48157248157248156, 0.4987714987714988, 0.4864864864864865, 0.4864864864864865, 0.5110565110565111, 0.5454545454545454, 0.5036855036855037, 0.47174447174447176, 0.48894348894348894, 0.4619164619164619, 0.48402948402948404], 0.8: [0.343980343980344, 0.32923832923832924, 0.3316953316953317, 0.343980343980344, 0.36855036855036855, 0.37346437346437344, 0.32678132678132676, 0.4103194103194103, 0.35626535626535627, 0.36363636363636365, 0.36855036855036855, 0.3538083538083538, 0.3808353808353808, 0.3906633906633907, 0.32678132678132676, 0.35626535626535627, 0.3906633906633907, 0.37346437346437344, 0.3759213759213759, 0.36363636363636365, 0.3538083538083538, 0.35872235872235875, 0.3366093366093366, 0.343980343980344, 0.3808353808353808, 0.3366093366093366, 0.3955773955773956, 0.36117936117936117, 0.3538083538083538, 0.3488943488943489, 0.37346437346437344, 0.343980343980344, 0.36363636363636365, 0.371007371007371, 0.33415233415233414, 0.32186732186732187, 0.3808353808353808, 0.36363636363636365, 0.32678132678132676, 0.3857493857493858, 0.40786240786240785, 0.36609336609336607, 0.3316953316953317, 0.33906633906633904, 0.3415233415233415, 0.35872235872235875, 0.35872235872235875, 0.40786240786240785, 0.343980343980344, 0.3538083538083538, 0.3783783783783784, 0.3488943488943489, 0.35872235872235875, 0.35872235872235875, 0.36117936117936117, 0.37346437346437344, 0.371007371007371, 0.3366093366093366, 0.40786240786240785, 0.39803439803439805, 0.343980343980344, 0.36117936117936117, 0.35872235872235875, 0.37346437346437344, 0.32678132678132676, 0.3366093366093366, 0.33906633906633904, 0.3144963144963145, 0.3464373464373464, 0.3194103194103194, 0.3366093366093366, 0.3144963144963145, 0.343980343980344, 0.3488943488943489, 0.3759213759213759, 0.31695331695331697, 0.3464373464373464, 0.3759213759213759, 0.28746928746928746, 0.3488943488943489], 1.0: [0.2727272727272727, 0.25307125307125306, 0.25061425061425063, 0.25307125307125306, 0.26044226044226043, 0.2751842751842752, 0.2751842751842752, 0.26044226044226043, 0.2678132678132678, 0.29975429975429974, 0.2751842751842752, 0.25061425061425063, 0.2457002457002457, 0.2628992628992629, 0.2727272727272727, 0.27764127764127766, 0.2678132678132678, 0.2678132678132678, 0.2678132678132678, 0.31203931203931207, 0.2628992628992629, 0.26044226044226043, 0.2457002457002457, 0.29484029484029484, 0.26535626535626533, 0.2285012285012285, 0.21867321867321868, 0.2702702702702703, 0.2628992628992629, 0.257985257985258, 0.24815724815724816, 0.25552825552825553, 0.23832923832923833, 0.24815724815724816, 0.24815724815724816, 0.2457002457002457, 0.22113022113022113, 0.20147420147420148, 0.257985257985258, 0.2972972972972973, 0.32186732186732187, 0.27764127764127766, 0.2702702702702703, 0.24815724815724816, 0.29975429975429974, 0.2334152334152334, 0.2628992628992629, 0.257985257985258, 0.2702702702702703, 0.26044226044226043, 0.2285012285012285, 0.29238329238329236, 0.2457002457002457, 0.27764127764127766, 0.2972972972972973, 0.2628992628992629, 0.26044226044226043, 0.2727272727272727, 0.2457002457002457, 0.25061425061425063, 0.2702702702702703, 0.2113022113022113, 0.2334152334152334, 0.28255528255528256, 0.25061425061425063, 0.2678132678132678, 0.21621621621621623, 0.25307125307125306, 0.27764127764127766, 0.2727272727272727, 0.2751842751842752, 0.23587223587223588, 0.25307125307125306, 0.23832923832923833, 0.2285012285012285, 0.24324324324324326, 0.23587223587223588, 0.23832923832923833, 0.21867321867321868, 0.257985257985258]}}\n"
     ]
    }
   ],
   "source": [
    "print(results_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reward = {}\n",
    "\n",
    "for threshold in [0.3, 0.5, 0.7, 0.9]:\n",
    "    results_reward[threshold] = {}\n",
    "    for snr in [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        results_reward[threshold][snr] = []\n",
    "        for subdir in range(4):\n",
    "            full_path = path + str(subdir) + '/20000'\n",
    "            network.load_state_dict(torch.load(full_path + '/network'))\n",
    "            for result in test_env(False, threshold, snr, 20):\n",
    "                results_reward[threshold][snr].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.3: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [92, 35, 156, 35, 147, 35, 167, 117, 35, 30, 35, 35, 63, 142, 30, 35, 83, 30, 67, 35, 63, 35, 35, 53, 30, 53, 30, 35, 35, 35, 30, 53, 117, 30, 35, 35, 35, 30, 35, 35, 63, 63, 53, 35, 72, 30, 35, 53, 30, 35, 30, 35, 131, 35, 5, 35, 57, 63, 172, 121, 35, 35, 116, 182, 35, 53, 136, 102, 35, 53, 35, 53, 35, 63, 5, 111, 63, 53, 35, 35], 0.4: [10, 25, 15, 0, 25, 0, 30, 0, 10, 25, 5, 25, 15, 25, 30, 10, 0, 5, 5, 5, 0, 10, 5, 10, 25, 0, 0, 0, 30, 0, 15, 0, 15, 0, 0, 10, 5, 10, 0, 35, 0, 10, 10, 30, 30, 10, 10, 10, 25, 15, 5, 0, 25, 0, 10, 0, 25, 25, 10, 25, 5, 0, 0, 5, 5, 0, 15, 0, 10, 15, 30, 10, 25, 15, 5, 10, 0, 5, 0, 15], 0.6: [0, 5, 0, 0, 35, 0, 10, 0, 10, 5, 0, 10, 0, 0, 0, 0, 5, 25, 5, 0, 0, 0, 0, 0, 10, 0, 5, 15, 0, 0, 0, 0, 0, 10, 0, 10, 0, 5, 25, 10, 0, 0, 0, 0, 0, 10, 10, 10, 0, 0, 0, 0, 0, 10, 0, 0, 10, 10, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0.8: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0], 1.0: [0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0]}, 0.5: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [53, 30, 35, 53, 53, 63, 30, 30, 35, 35, 35, 111, 35, 53, 53, 35, 35, 35, 35, 98, 121, 35, 30, 63, 30, 53, 35, 63, 35, 53, 67, 53, 30, 30, 30, 127, 112, 53, 35, 63, 35, 35, 72, 30, 63, 67, 53, 35, 111, 35, 63, 35, 53, 35, 63, 35, 35, 121, 35, 167, 35, 132, 147, 187, 223, 67, 67, 53, 63, 15, 35, 53, 240, 67, 53, 157, 233, 63, 15, 131], 0.4: [5, 5, 25, 25, 5, 15, 0, 25, 30, 10, 15, 15, 25, 0, 10, 10, 10, 0, 5, 15, 0, 0, 0, 0, 15, 25, 10, 15, 30, 25, 10, 25, 5, 25, 5, 5, 5, 0, 5, 15, 0, 5, 30, 10, 15, 25, 10, 5, 25, 10, 30, 0, 25, 30, 0, 0, 30, 10, 25, 15, 25, 5, 15, 25, 0, 0, 5, 0, 0, 30, 25, 10, 5, 10, 5, 15, 25, 15, 10, 15], 0.6: [10, 0, 0, 10, 0, 0, 0, 10, 0, 10, 0, 0, 10, 0, 25, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 10, 0, 5, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 10, 10, 25, 0, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 10, 10, 0, 0, 10, 0, 5, 0, 0, 0], 0.8: [0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10], 1.0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 0.7: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [63, 35, 30, 167, 202, 35, 35, 35, 35, 131, 35, 63, 35, 35, 35, 77, 127, 30, 35, 63, 92, 30, 35, 35, 35, 116, 25, 76, 30, 35, 30, 82, 63, 53, 35, 35, 97, 131, 178, 5, 30, 35, 35, 30, 53, 35, 25, 53, 53, 25, 5, 53, 30, 35, 25, 63, 25, 30, 35, 35, 53, 35, 35, 35, 96, 35, 35, 35, 53, 30, 30, 35, 35, 72, 35, 25, 151, 35, 96, 63], 0.4: [5, 0, 25, 5, 5, 30, 0, 10, 25, 0, 10, 5, 5, 0, 0, 10, 10, 35, 10, 25, 5, 0, 0, 0, 0, 5, 5, 0, 5, 15, 0, 25, 5, 10, 10, 0, 0, 5, 5, 30, 25, 10, 5, 5, 10, 10, 25, 0, 15, 15, 25, 15, 25, 25, 5, 30, 10, 0, 25, 15, 10, 10, 0, 35, 0, 25, 10, 10, 5, 5, 0, 25, 0, 0, 0, 0, 10, 10, 10, 10], 0.6: [5, 0, 0, 0, 0, 0, 10, 0, 10, 25, 0, 0, 15, 0, 10, 0, 0, 25, 0, 0, 10, 0, 5, 0, 10, 5, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 5, 0, 10, 0, 10, 0, 10, 0, 10, 25, 5, 10, 10, 10, 0, 0, 10, 10, 10, 0, 0, 10, 0, 0, 10], 0.8: [0, 0, 10, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 10, 0, 10, 10, 10, 0, 0, 0, 10, 0, 0, 10, 0, 0, 0, 0, 10, 10, 0, 0, 25, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 5, 0, 0, 0, 0, 10, 0, 0, 10], 1.0: [10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0]}, 0.9: {0.0: [350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350], 0.2: [53, 35, 25, 30, 30, 30, 30, 35, 101, 35, 63, 10, 35, 53, 30, 35, 53, 35, 30, 30, 35, 116, 111, 30, 35, 35, 35, 35, 101, 35, 30, 63, 53, 35, 35, 25, 35, 35, 35, 30, 67, 35, 152, 35, 53, 53, 5, 30, 5, 35, 35, 30, 35, 35, 97, 35, 25, 30, 30, 30, 30, 35, 30, 61, 67, 30, 63, 30, 15, 15, 53, 5, 30, 15, 59, 30, 30, 84, 15, 30], 0.4: [0, 15, 15, 15, 0, 10, 5, 30, 30, 0, 10, 0, 10, 35, 5, 25, 5, 25, 25, 10, 10, 30, 0, 20, 0, 30, 5, 25, 5, 5, 25, 25, 0, 10, 25, 5, 10, 5, 5, 0, 5, 10, 25, 10, 0, 25, 10, 30, 30, 0, 30, 25, 10, 15, 10, 10, 25, 10, 15, 0, 0, 15, 25, 0, 0, 10, 5, 25, 5, 25, 5, 30, 25, 35, 10, 30, 10, 25, 0, 0], 0.6: [10, 0, 10, 0, 10, 0, 0, 10, 0, 0, 0, 25, 0, 0, 0, 0, 0, 10, 0, 10, 0, 10, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 10, 0, 0, 10, 0, 0, 10, 25, 0, 10, 0, 0, 10, 0, 0, 5, 0, 0, 0, 10, 0, 10, 0, 0, 5, 10, 0, 0, 0, 10, 0, 10, 0, 0, 10, 0, 0, 10, 10, 0, 0, 10, 0], 0.8: [0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 25, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 0, 10, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 10, 5, 0, 10, 0, 10, 10, 0, 0, 0, 0], 1.0: [10, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 25, 0, 10, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 10, 10, 10, 10, 10, 0, 0, 0, 10, 0, 0, 0, 0, 10, 0, 0, 0, 5, 0, 0, 10, 0, 0]}}\n"
     ]
    }
   ],
   "source": [
    "print(results_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_timing(its):\n",
    "    for _ in range(its):\n",
    "        for action in raw_actions:\n",
    "            vec = 0\n",
    "            for token in tokenizer(action):\n",
    "                vec += word2vec_model[token]\n",
    "\n",
    "            sampled_noise = noise.sample().numpy()\n",
    "            normalized_noise = snr * np.linalg.norm(vec) * sampled_noise / np.linalg.norm(sampled_noise)            \n",
    "            ground_truth = torch.Tensor(vec + normalized_noise).to(device).unsqueeze(0)\n",
    "\n",
    "            deepcs_output = network(ground_truth, True).squeeze(0)\n",
    "            list_of_words = []\n",
    "            for idx in range(len(deepcs_output)):\n",
    "                if deepcs_output[idx] > threshold:\n",
    "                    list_of_words.append(idx)\n",
    "\n",
    "            _, text_command = agent._select_eps_greedy_action(0, list_of_words, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3475349499999993\n"
     ]
    }
   ],
   "source": [
    "tick= time.clock()\n",
    "test_timing(20)\n",
    "tock = time.clock()\n",
    "print((tock - tick)/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#396ab1', '#da7c30', '#3e9651', '#cc2529', '#94823d', '#535154', '#006400', '#00FF00', '#800000', '#F08080', '#FFFF00', '#000000', '#C0C0C0']\n",
    "facecolors = ['#7293cb', '#e1974c', '#84ba5b', '#d35e60', '#ccc210', '#808585']\n",
    "\n",
    "f, axarr = pl.subplots(1, 1, figsize=(6, 3))\n",
    "\n",
    "idx = 0\n",
    "for test_name in results_reward:\n",
    "    avg = [res[0] for res in results_reward[test_name]]\n",
    "    std = [res[1] for res in results_reward[test_name]]\n",
    "    pl.plot(snr, avg, label=test_name, color=colors[idx])\n",
    "    pl.fill_between(snr, np.array(avg) - np.array(std), np.array(avg) + np.array(std), facecolor=facecolors[idx], alpha=0.2, interpolate=True)\n",
    "    idx += 1\n",
    "\n",
    "leg = pl.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), shadow=True, ncol=3, fontsize=10)\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(3.0)\n",
    "    \n",
    "#pl.suptitle('Egg Quest, Minimal Action Set,\\n GloVe, Training with K=all', fontsize=20, y=1.1)\n",
    "pl.xlabel('SnR')\n",
    "pl.ylabel('Reward')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "omp = OrthogonalMatchingPursuit(n_nonzero_coefs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_omp(additional_prints, snr, its):\n",
    "    runs = []\n",
    "    for _ in range(its):\n",
    "        accurate = 0\n",
    "        for action in raw_actions:\n",
    "            vec = 0\n",
    "            for token in tokenizer(action):\n",
    "                vec += word2vec_model[token]\n",
    "\n",
    "            sampled_noise = noise.sample().numpy()\n",
    "            normalized_noise = snr * np.linalg.norm(vec) * sampled_noise / np.linalg.norm(sampled_noise)            \n",
    "            ground_truth = vec + normalized_noise\n",
    "\n",
    "            omp.fit(agent.word_embeddings.cpu().numpy().T, ground_truth)\n",
    "            coef = omp.coef_\n",
    "            idx_r, = coef.nonzero()\n",
    "\n",
    "            list_of_words = []\n",
    "            for idx in idx_r:\n",
    "                if coef[idx] > 0.5:\n",
    "                    list_of_words.append(idx)\n",
    "\n",
    "            _, text_command = agent._select_eps_greedy_action(0, list_of_words, None)\n",
    "\n",
    "            if set(tokenizer(action)) == set(tokenizer(text_command)):\n",
    "                accurate += 1\n",
    "            elif additional_prints:\n",
    "                print(tokenizer(text_command))\n",
    "                print(tokenizer(action))\n",
    "\n",
    "        runs.append(accurate * 1.0 / len(raw_actions))\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['out', 'and', 'rope', 'knife']\n",
      "['get', 'rope', 'and', 'knife']\n",
      "['railing', 'tie', 'rope', 'down']\n",
      "['tie', 'rope', 'to', 'railing']\n",
      "['go', 'torch']\n",
      "['get', 'torch']\n",
      "['to', 'and', 'torch', 'lamp']\n",
      "['take', 'torch', 'and', 'lamp']\n",
      "['case', 'coffin', 'in', 'to']\n",
      "['put', 'coffin', 'in', 'case']\n",
      "['of', 'skull', 'case', 'wait']\n",
      "['put', 'skull', 'in', 'case']\n",
      "['case', 'bar', 'to']\n",
      "['put', 'bar', 'in', 'case']\n",
      "['out', 'bag', 'and', 'knife']\n",
      "['get', 'knife', 'and', 'bag']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['put', 'case', 'bag']\n",
      "['put', 'bag', 'in', 'case']\n",
      "['pile', 'case', 'in', 'button']\n",
      "['put', 'trunk', 'in', 'case']\n",
      "['trident', 'case', 'in', 'to']\n",
      "['put', 'trident', 'in', 'case']\n",
      "['boat', 'tie', 'sword', 'in']\n",
      "['throw', 'sceptre', 'in', 'boat']\n",
      "['of', 'out', 'boat', 'wait']\n",
      "['get', 'out', 'of', 'boat']\n",
      "['case', 'in', 'to', 'sceptre']\n",
      "['put', 'sceptre', 'in', 'case']\n",
      "['case', 'in', 'to', 'pot']\n",
      "['put', 'pot', 'in', 'case']\n",
      "['case', 'from', 'scarab']\n",
      "['put', 'scarab', 'in', 'case']\n",
      "['go', 'torch']\n",
      "['get', 'torch']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['case', 'from', 'chalice']\n",
      "['put', 'chalice', 'in', 'case']\n",
      "['case', 'in', 'egg', 'to']\n",
      "['put', 'egg', 'in', 'case']\n",
      "['case', 'bauble', 'in', 'up']\n",
      "['put', 'bauble', 'in', 'case']\n",
      "['case', 'jewels', 'in', 'to']\n",
      "['put', 'jewels', 'in', 'case']\n",
      "['basket', 'in', 'torch', 'up']\n",
      "['put', 'torch', 'in', 'basket']\n",
      "['basket', 'in', 'screwdriver', 'up']\n",
      "['put', 'screwdriver', 'in', 'basket']\n",
      "['basket', 'in', 'coal', 'up']\n",
      "['put', 'coal', 'in', 'basket']\n",
      "['basket', 'all', 'up']\n",
      "['get', 'all', 'from', 'basket']\n",
      "['from', 'coal', 'shovel']\n",
      "['put', 'coal', 'in', 'machine']\n",
      "['basket', 'in', 'diamond', 'up']\n",
      "['put', 'diamond', 'in', 'basket']\n",
      "['basket', 'in', 'torch', 'up']\n",
      "['put', 'torch', 'in', 'basket']\n",
      "['basket', 'in', 'screwdriver', 'up']\n",
      "['put', 'screwdriver', 'in', 'basket']\n",
      "['basket', 'all', 'up']\n",
      "['get', 'all', 'from', 'basket']\n",
      "['case', 'in', 'to', 'torch']\n",
      "['put', 'torch', 'in', 'case']\n",
      "['case', 'bracelet', 'in', 'up']\n",
      "['put', 'bracelet', 'in', 'case']\n",
      "['figurine', 'case', 'in', 'up']\n",
      "['put', 'figurine', 'in', 'case']\n",
      "['pile', 'case', 'in', 'button']\n",
      "['put', 'trunk', 'in', 'case']\n",
      "['go', 'map']\n",
      "['get', 'map']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n",
      "/home/deep/pytorch/lib/python3.6/site-packages/sklearn/linear_model/omp.py:387: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  copy_X=copy_X, return_path=return_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.914004914004914]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_omp(True, 0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
