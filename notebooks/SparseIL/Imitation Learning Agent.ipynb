{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.downloader as glove_api\n",
    "import os\n",
    "\n",
    "from ZorkGym.text_utils.text_parser import BagOfWords, Word2Vec, TextParser, tokenizer\n",
    "from agents.OMP_DDPG import OMPDDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.enabled = False\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_padding(list_of_embeddings, length, embedding_length):\n",
    "    zero_vec = np.zeros(embedding_length)\n",
    "    for _ in range(length - len(list_of_embeddings)):\n",
    "        list_of_embeddings.append(zero_vec)\n",
    "    return list_of_embeddings[:length]\n",
    "\n",
    "\n",
    "def word2vec_sum(list_of_embeddings, embedding_length):\n",
    "    ret_value = np.zeros(embedding_length)\n",
    "    for embedding in list_of_embeddings:\n",
    "        ret_value += embedding\n",
    "    return ret_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = glove_api.load('glove-wiki-gigaword-50')\n",
    "embedding_size = word2vec_model.vector_size\n",
    "word2vec_parser = Word2Vec(type_func=lambda x: torch.FloatTensor(x).to(device).unsqueeze(0),\n",
    "                           word2vec_model=word2vec_model,\n",
    "                           return_func=lambda x: word2vec_padding(x, 65, embedding_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd() + '/data/zork_walkthrough.txt', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/chen/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "states = [word2vec_parser(state) for state in data['states']]\n",
    "raw_actions = data['actions']\n",
    "actions = []\n",
    "\n",
    "for action in raw_actions:\n",
    "    vect = 0\n",
    "    for token in tokenizer(action):\n",
    "        vect += word2vec_model[token]\n",
    "    actions.append(torch.Tensor(vect).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['west', 'of', 'house', 'you', 'are', 'standing', 'in', 'an', 'open', 'field', 'west', 'of', 'a', 'white', 'house', 'with', 'a', 'boarded', 'front', 'door', 'there', 'is', 'a', 'small', 'mailbox', 'here'], []]\n",
      "north\n",
      "[['north', 'of', 'house', 'you', 'are', 'facing', 'the', 'north', 'side', 'of', 'a', 'white', 'house', 'there', 'is', 'no', 'door', 'here', 'and', 'all', 'the', 'windows', 'are', 'boarded', 'up', 'to', 'the', 'north', 'a', 'narrow', 'path', 'winds', 'through', 'the', 'trees'], []]\n",
      "north\n",
      "[['forest', 'path', 'this', 'is', 'a', 'path', 'winding', 'through', 'a', 'dimly', 'lit', 'forest', 'the', 'path', 'heads', 'north', 'south', 'here', 'one', 'particularly', 'large', 'tree', 'with', 'some', 'low', 'branches', 'stands', 'at', 'the', 'edge', 'of', 'the', 'path'], []]\n",
      "up\n",
      "[['up', 'a', 'tree', 'you', 'are', 'about', 'feet', 'above', 'the', 'ground', 'nestled', 'among', 'some', 'large', 'branches', 'the', 'nearest', 'branch', 'above', 'you', 'is', 'above', 'your', 'reach', 'beside', 'you', 'on', 'the', 'branch', 'is', 'a', 'small', 'bird', 's', 'nest', 'in', 'the', 'bird', 's', 'nest', 'is', 'a', 'large', 'egg', 'encrusted', 'with', 'precious', 'jewels', 'apparently', 'scavenged', 'by', 'a', 'childless', 'songbird', 'the', 'egg', 'is', 'covered', 'with', 'fine', 'gold', 'inlay', 'and', 'ornamented', 'in', 'lapis', 'lazuli', 'and', 'mother', 'of', 'pearl', 'unlike', 'most', 'eggs', 'this', 'one', 'is', 'hinged', 'and', 'closed', 'with', 'a', 'delicate', 'looking', 'clasp', 'the', 'egg', 'appears', 'extremely', 'fragile'], []]\n",
      "Get egg\n",
      "[['up', 'a', 'tree', 'you', 'are', 'about', 'feet', 'above', 'the', 'ground', 'nestled', 'among', 'some', 'large', 'branches', 'the', 'nearest', 'branch', 'above', 'you', 'is', 'above', 'your', 'reach', 'beside', 'you', 'on', 'the', 'branch', 'is', 'a', 'small', 'bird', 's', 'nest'], ['jewel', 'encrusted', 'egg']]\n",
      "down\n",
      "[['forest', 'path', 'this', 'is', 'a', 'path', 'winding', 'through', 'a', 'dimly', 'lit', 'forest', 'the', 'path', 'heads', 'north', 'south', 'here', 'one', 'particularly', 'large', 'tree', 'with', 'some', 'low', 'branches', 'stands', 'at', 'the', 'edge', 'of', 'the', 'path', 'you', 'hear', 'in', 'the', 'distance', 'the', 'chirping', 'of', 'a', 'song', 'bird'], ['jewel', 'encrusted', 'egg']]\n",
      "south\n",
      "[['north', 'of', 'house', 'you', 'are', 'facing', 'the', 'north', 'side', 'of', 'a', 'white', 'house', 'there', 'is', 'no', 'door', 'here', 'and', 'all', 'the', 'windows', 'are', 'boarded', 'up', 'to', 'the', 'north', 'a', 'narrow', 'path', 'winds', 'through', 'the', 'trees'], ['jewel', 'encrusted', 'egg']]\n",
      "east\n",
      "[['behind', 'house', 'you', 'are', 'behind', 'the', 'white', 'house', 'a', 'path', 'leads', 'into', 'the', 'forest', 'to', 'the', 'east', 'in', 'one', 'corner', 'of', 'the', 'house', 'there', 'is', 'a', 'small', 'window', 'which', 'is', 'slightly', 'ajar'], ['jewel', 'encrusted', 'egg']]\n",
      "Open window\n",
      "[['behind', 'house', 'you', 'are', 'behind', 'the', 'white', 'house', 'a', 'path', 'leads', 'into', 'the', 'forest', 'to', 'the', 'east', 'in', 'one', 'corner', 'of', 'the', 'house', 'there', 'is', 'a', 'small', 'window', 'which', 'is', 'open'], ['jewel', 'encrusted', 'egg']]\n",
      "west\n",
      "[['kitchen', 'you', 'are', 'in', 'the', 'kitchen', 'of', 'the', 'white', 'house', 'a', 'table', 'seems', 'to', 'have', 'been', 'used', 'recently', 'for', 'the', 'preparation', 'of', 'food', 'a', 'passage', 'leads', 'to', 'the', 'west', 'and', 'a', 'dark', 'staircase', 'can', 'be', 'seen', 'leading', 'upward', 'a', 'dark', 'chimney', 'leads', 'down', 'and', 'to', 'the', 'east', 'is', 'a', 'small', 'window', 'which', 'is', 'open', 'on', 'the', 'table', 'is', 'an', 'elongated', 'brown', 'sack', 'smelling', 'of', 'hot', 'peppers', 'a', 'bottle', 'is', 'sitting', 'on', 'the', 'table', 'the', 'glass', 'bottle', 'contains', 'a', 'quantity', 'of', 'water'], ['jewel', 'encrusted', 'egg']]\n",
      "west\n",
      "[['living', 'room', 'you', 'are', 'in', 'the', 'living', 'room', 'there', 'is', 'a', 'doorway', 'to', 'the', 'east', 'a', 'wooden', 'door', 'with', 'strange', 'gothic', 'lettering', 'to', 'the', 'west', 'which', 'appears', 'to', 'be', 'nailed', 'shut', 'a', 'trophy', 'case', 'and', 'a', 'large', 'oriental', 'rug', 'in', 'the', 'center', 'of', 'the', 'room', 'above', 'the', 'trophy', 'case', 'hangs', 'an', 'elvish', 'sword', 'of', 'great', 'antiquity', 'a', 'battery', 'powered', 'brass', 'lantern', 'is', 'on', 'the', 'trophy', 'case'], ['jewel', 'encrusted', 'egg']]\n",
      "Get lamp\n",
      "[['living', 'room', 'you', 'are', 'in', 'the', 'living', 'room', 'there', 'is', 'a', 'doorway', 'to', 'the', 'east', 'a', 'wooden', 'door', 'with', 'strange', 'gothic', 'lettering', 'to', 'the', 'west', 'which', 'appears', 'to', 'be', 'nailed', 'shut', 'a', 'trophy', 'case', 'and', 'a', 'large', 'oriental', 'rug', 'in', 'the', 'center', 'of', 'the', 'room', 'above', 'the', 'trophy', 'case', 'hangs', 'an', 'elvish', 'sword', 'of', 'great', 'antiquity'], ['brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "Get sword\n",
      "[['living', 'room', 'you', 'are', 'in', 'the', 'living', 'room', 'there', 'is', 'a', 'doorway', 'to', 'the', 'east', 'a', 'wooden', 'door', 'with', 'strange', 'gothic', 'lettering', 'to', 'the', 'west', 'which', 'appears', 'to', 'be', 'nailed', 'shut', 'a', 'trophy', 'case', 'and', 'a', 'large', 'oriental', 'rug', 'in', 'the', 'center', 'of', 'the', 'room'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "Move rug\n",
      "[['living', 'room', 'you', 'are', 'in', 'the', 'living', 'room', 'there', 'is', 'a', 'doorway', 'to', 'the', 'east', 'a', 'wooden', 'door', 'with', 'strange', 'gothic', 'lettering', 'to', 'the', 'west', 'which', 'appears', 'to', 'be', 'nailed', 'shut', 'a', 'trophy', 'case', 'and', 'a', 'closed', 'trap', 'door', 'at', 'your', 'feet'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "Open trapdoor\n",
      "[['living', 'room', 'you', 'are', 'in', 'the', 'living', 'room', 'there', 'is', 'a', 'doorway', 'to', 'the', 'east', 'a', 'wooden', 'door', 'with', 'strange', 'gothic', 'lettering', 'to', 'the', 'west', 'which', 'appears', 'to', 'be', 'nailed', 'shut', 'a', 'trophy', 'case', 'and', 'a', 'rug', 'lying', 'beside', 'an', 'open', 'trap', 'door'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "down\n",
      "[['it', 'is', 'pitch', 'black', 'you', 'are', 'likely', 'to', 'be', 'eaten', 'by', 'a', 'grue'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "Light lamp\n",
      "[['cellar', 'you', 'are', 'in', 'a', 'dark', 'and', 'damp', 'cellar', 'with', 'a', 'narrow', 'passageway', 'leading', 'north', 'and', 'a', 'crawlway', 'to', 'the', 'south', 'on', 'the', 'west', 'is', 'the', 'bottom', 'of', 'a', 'steep', 'metal', 'ramp', 'which', 'is', 'unclimbable'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "north\n",
      "[['the', 'troll', 'room', 'this', 'is', 'a', 'small', 'room', 'with', 'passages', 'to', 'the', 'east', 'and', 'south', 'and', 'a', 'forbidding', 'hole', 'leading', 'west', 'bloodstains', 'and', 'deep', 'scratches', 'perhaps', 'made', 'by', 'an', 'axe', 'mar', 'the', 'walls', 'a', 'nasty', 'looking', 'troll', 'brandishing', 'a', 'bloody', 'axe', 'blocks', 'all', 'passages', 'out', 'of', 'the', 'room', 'your', 'sword', 'has', 'begun', 'to', 'glow', 'very', 'brightly', 'the', 'axe', 'gets', 'you', 'right', 'in', 'the', 'side', 'ouch'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "Kill troll with sword\n",
      "[['a', 'good', 'stroke', 'but', 'it', 's', 'too', 'slow', 'the', 'troll', 'dodges', 'the', 'axe', 'crashes', 'against', 'the', 'rock', 'throwing', 'sparks'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n",
      "Kill troll with sword\n",
      "[['the', 'troll', 'takes', 'a', 'fatal', 'blow', 'and', 'slumps', 'to', 'the', 'floor', 'dead', 'almost', 'as', 'soon', 'as', 'the', 'troll', 'breathes', 'his', 'last', 'breath', 'a', 'cloud', 'of', 'sinister', 'black', 'fog', 'envelops', 'him', 'and', 'when', 'the', 'fog', 'lifts', 'the', 'carcass', 'has', 'disappeared', 'your', 'sword', 'is', 'no', 'longer', 'glowing'], ['sword', 'brass', 'lantern', 'jewel', 'encrusted', 'egg']]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-386cb7493977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'states'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'states'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for idx in range(len(data['states'])):\n",
    "    print(data['states'][idx])\n",
    "    print(data['actions'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create vocabluary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "for action in raw_actions:\n",
    "    for word in tokenizer(action):\n",
    "        words.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Agent using Imitation Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_vocabulary = {}\n",
    "for word in words:\n",
    "    action_vocabulary[word] = word2vec_model[word]\n",
    "action_vocabulary[''] = [0 for _ in range(len(action_vocabulary['open']))]\n",
    "\n",
    "embedding_size = len(action_vocabulary['open'])\n",
    "\n",
    "train_params = {\n",
    "    'seed': 12,\n",
    "    'number_of_neighbors': -1\n",
    "}\n",
    "test_params = {\n",
    "    'nn=-1': {'number_of_neighbors': -1},\n",
    "    'nn=1': {'number_of_neighbors': 1},\n",
    "    'nn=3': {'number_of_neighbors': 3},\n",
    "    'nn=11': {'number_of_neighbors': 11},\n",
    "}\n",
    "\n",
    "agent = OMPDDPG(actions=action_vocabulary,\n",
    "                state_parser=word2vec_parser,\n",
    "                embedding_size=embedding_size,\n",
    "                input_length=embedding_size,\n",
    "                input_width=65,\n",
    "                history_size=1,\n",
    "                model_type='CNN',\n",
    "                device=device,\n",
    "                pomdp_mode=True,\n",
    "                loss_weighting=1.0,\n",
    "                linear=False,\n",
    "                improved_omp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = agent._create_optimizer(lr=0.0001)\n",
    "batch_size = 32\n",
    "num_iters = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(num_iters):\n",
    "    indices = np.random.randint(0, len(actions), batch_size)\n",
    "    obs_batch = []\n",
    "    action_batch = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        obs_batch.append(states[idx])\n",
    "        action_batch.append(actions[idx])\n",
    "        \n",
    "    obs_batch = torch.stack(obs_batch).detach()\n",
    "    action_batch = torch.stack(action_batch).detach()\n",
    "    \n",
    "    optimizer[0].zero_grad()\n",
    "    predicted_actions = agent.network[0](obs_batch)\n",
    "    loss = F.mse_loss(predicted_actions, action_batch.view(batch_size, -1).detach())\n",
    "    loss.backward()\n",
    "    print('Iteration: ' + str(loss.item()))\n",
    "    optimizer[0].step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
